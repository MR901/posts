<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" data-mode="light">
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  ><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Comprehensive Guide to Prompt Engineering and LLMs" />
<meta property="og:locale" content="en" />
<meta name="description" content="Comprehensive guide to prompt engineering: foundations, techniques (zero/few-shot, CoT/ToT, RAG, ReAct), reasoning LLMs, agents, evaluation, and alignment." />
<meta property="og:description" content="Comprehensive guide to prompt engineering: foundations, techniques (zero/few-shot, CoT/ToT, RAG, ReAct), reasoning LLMs, agents, evaluation, and alignment." />
<link rel="canonical" href="https://mr901.github.io/posts/prompting-engineering/" />
<meta property="og:url" content="https://mr901.github.io/posts/prompting-engineering/" />
<meta property="og:site_name" content="Posts by MR901" />
<meta property="og:image" content="https://mr901.github.io/posts/attachments/posts/2025-10-05-prompting-engineering/images/prompt_engineering.png" />
<meta property="og:image:alt" content="Prompt Engineering" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-05T00:00:00+05:30" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://mr901.github.io/posts/attachments/posts/2025-10-05-prompting-engineering/images/prompt_engineering.png" />
<meta name="twitter:image:alt" content="Prompt Engineering" />
<meta property="twitter:title" content="Comprehensive Guide to Prompt Engineering and LLMs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-05T00:00:00+05:30","datePublished":"2025-10-05T00:00:00+05:30","description":"Comprehensive guide to prompt engineering: foundations, techniques (zero/few-shot, CoT/ToT, RAG, ReAct), reasoning LLMs, agents, evaluation, and alignment.","headline":"Comprehensive Guide to Prompt Engineering and LLMs","image":{"alt":"Prompt Engineering","url":"https://mr901.github.io/posts/attachments/posts/2025-10-05-prompting-engineering/images/prompt_engineering.png","@type":"imageObject"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mr901.github.io/posts/prompting-engineering/"},"url":"https://mr901.github.io/posts/prompting-engineering/"}</script>
<!-- End Jekyll SEO tag -->


  <title>Comprehensive Guide to Prompt Engineering and LLMs | Posts by MR901
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/posts/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/posts/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/posts/assets/img/favicons/favicon-16x16.png">

<link rel="shortcut icon" href="/posts/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Posts by MR901">
<meta name="application-name" content="Posts by MR901">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/posts/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  <!-- Resource Hints -->
  

  <!-- Bootstrap -->
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/css/bootstrap.min.css">
  

  <!-- Theme style -->
  <link rel="stylesheet" href="/posts/assets/css/jekyll-theme-chirpy.css">

  <!-- Web Font -->
  <link rel="stylesheet" href="/posts/assets/lib/fonts/main.css">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="/posts/assets/lib/fontawesome-free/css/all.min.css">

  <!-- 3rd-party Dependencies -->

  
    <link rel="stylesheet" href="/posts/assets/lib/tocbot/tocbot.min.css">
  

  
    <link rel="stylesheet" href="/posts/assets/lib/loading-attribute-polyfill/loading-attribute-polyfill.min.css">
  

  
    <!-- Image Popup -->
    <link rel="stylesheet" href="/posts/assets/lib/glightbox/glightbox.min.css">
  

  <!-- Scripts -->

  <script src="/posts/assets/js/dist/theme.min.js"></script>

  <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    <script defer src="/posts/assets/lib/simple-jekyll-search/simple-jekyll-search.min.js"></script>
  

  
    <script defer src="/posts/assets/lib/loading-attribute-polyfill/loading-attribute-polyfill.umd.min.js"></script>
  

  
    <script defer src="/posts/assets/lib/glightbox/glightbox.min.js"></script>
  

  
    <script defer src="/posts/assets/lib/clipboard/clipboard.min.js"></script>
  

  
    <script defer src="/posts/assets/lib/dayjs/dayjs.min.js"></script>
  

  
    <script defer src="/posts/assets/lib/dayjs/locale/en.js"></script>
  

  
    <script defer src="/posts/assets/lib/dayjs/plugin/relativeTime.js"></script>
  

  
    <script defer src="/posts/assets/lib/dayjs/plugin/localizedFormat.js"></script>
  

  
    <script defer src="/posts/assets/lib/tocbot/tocbot.min.js"></script>
  









<script defer src="/posts/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script src="/posts/assets/js/data/mathjax.js"></script>
  <script async src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="/posts/assets/lib/mathjax/tex-chtml.js"></script>


<!-- Pageviews -->

  

  



  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/posts/" id="avatar" class="rounded-circle"><img src="https://avatars.githubusercontent.com/u/20877166?v=4" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a>

    <a class="site-title d-block" href="/posts/">Posts by MR901</a>
    <p class="site-subtitle fst-italic mb-0">Post on Machine Learning</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/posts/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/posts/timeline/" class="nav-link">
            <i class="fa-fw fas fa-clock"></i>
            

            <span>TIMELINE</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/posts/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/posts/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/posts/attachments/" class="nav-link">
            <i class="fa-fw fas fa-paperclip"></i>
            

            <span>ATTACHMENTS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/posts/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    

    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['mohitrajput901','gmail.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="https://www.linkedin.com/in/mr901"
          aria-label="linkedin"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-linkedin"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/posts/">Home</a>
            </span>

          
        
          
            
              <span>Comprehensive Guide to Prompt Engineering and LLMs</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link" aria-label="Search">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search id="search" class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->




  
  

  
    
      
      
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  

  


<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  

  
  

  




<!-- return -->










<article class="px-1" data-toc="true">
  <header>
    <h1 data-toc-skip>Comprehensive Guide to Prompt Engineering and LLMs</h1>
    
      <p class="post-desc fw-light mb-4">Comprehensive guide to prompt engineering: foundations, techniques (zero/few-shot, CoT/ToT, RAG, ReAct), reasoning LLMs, agents, evaluation, and alignment.</p>
    

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1759602600"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Oct  5, 2025
</time>

      </span>

      <!-- lastmod date -->
      

      
        
        
        

        

        <div class="mt-3 mb-3">
          <a href="/posts/attachments/posts/2025-10-05-prompting-engineering/images/prompt_engineering.png" class="popup img-link preview-img shimmer"><img src="/posts/attachments/posts/2025-10-05-prompting-engineering/images/prompt_engineering.png"  alt="Prompt Engineering" width="1200" height="630"  loading="lazy"></a><figcaption class="text-center pt-2 pb-2">Prompt Engineering</figcaption></div>
      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://github.com/mr901">Mohit Rajput</a>
            
          </em>
        </span>

        <div>
          <!-- pageviews -->
          

          <!-- read time -->
          <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="6321 words"
>
  <em>35 min</em> read</span>

        </div>
      </div>
    </div>
  </header>

  
    <div id="toc-bar" class="d-flex align-items-center justify-content-between invisible">
      <span class="label text-truncate">Comprehensive Guide to Prompt Engineering and LLMs</span>
      <button type="button" class="toc-trigger btn me-1">
        <i class="fa-solid fa-list-ul fa-fw"></i>
      </button>
    </div>

    <button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm">
      <span class="label ps-2 pe-1">Contents</span>
      <i class="fa-solid fa-angle-right fa-fw"></i>
    </button>

    <dialog id="toc-popup" class="p-0">
      <div class="header d-flex flex-row align-items-center justify-content-between">
        <div class="label text-truncate py-2 ms-4">Comprehensive Guide to Prompt Engineering and LLMs</div>
        <button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75">
          <i class="fas fa-close"></i>
        </button>
      </div>
      <div id="toc-popup-content" class="px-4 py-3 pb-4"></div>
    </dialog>
  

  <div class="content">
    <div class="section" id="part-1-foundations-of-prompt-engineering">
<h2 id="part-1-foundations-of-prompt-engineering"><span class="me-2">Part 1 – Foundations of Prompt Engineering</span><a href="#part-1-foundations-of-prompt-engineering" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>
<div class="section" id="introduction">
<h2 id="introduction"><span class="me-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering is the practice of crafting inputs that guide a Large Language Model (LLM) toward producing accurate, relevant, and controlled outputs.
It merges linguistic precision, computational understanding, and psychological insight into how instructions shape reasoning patterns within generative models.</p>
</div>
<div class="section" id="generative-ai-overview">
<h2 id="generative-ai-overview"><span class="me-2">Generative AI Overview</span><a href="#generative-ai-overview" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="definition">
<h3 id="definition"><span class="me-2">Definition</span><a href="#definition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Generative Artificial Intelligence (GenAI)</strong> refers to machine-learning systems capable of producing new content rather than classifying existing data.
Text, images, audio, and code are synthesized through probabilistic token prediction.</p>
</div>
<div class="section" id="core-principle">
<h3 id="core-principle"><span class="me-2">Core principle</span><a href="#core-principle" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>LLMs learn conditional probability distributions</strong></p>
<div class="math">
\begin{equation*}
P(\text{next token} | \text{previous tokens})
\end{equation*}
</div>
<p>Given a context of preceding tokens, the model predicts the most probable next token.
By repeating this process iteratively, it generates coherent sequences.</p>
</div>
<div class="section" id="architecture-snapshot-transformers">
<h3 id="architecture-snapshot-transformers"><span class="me-2">Architecture Snapshot – Transformers</span><a href="#architecture-snapshot-transformers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Transformers are the foundation of modern LLMs.
They use <strong>self-attention</strong> mechanisms to weigh contextual relationships between tokens.
<strong>Key components</strong></p>
<ul class="simple">
<li><strong>Embedding Layer</strong> – converts discrete tokens into high-dimensional vectors.</li>
<li><strong>Self-Attention Block</strong> – computes contextual similarity via query–key–value matrices.</li>
<li><strong>Feed-Forward Network</strong> – non-linear transformation applied to each position.</li>
<li><strong>Residual Connections + Layer Normalization</strong> – stabilize gradient flow.</li>
</ul>
</div>
<div class="section" id="tokenization-and-context">
<h3 id="tokenization-and-context"><span class="me-2">Tokenization and Context</span><a href="#tokenization-and-context" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A <strong>token</strong> is a basic unit of text (word, sub-word, or punctuation).
Each model has a maximum <strong>context window</strong>, the number of tokens it can attend to at once.
For instance, GPT-4-Turbo supports ≈ 128 k tokens.
Older models truncate or summarize input beyond their limit.</p>
</div>
<div class="section" id="limitations-of-llms">
<h3 id="limitations-of-llms"><span class="me-2">Limitations of LLMs</span><a href="#limitations-of-llms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>Finite Context:</strong> Memory restricted by context window.</li>
<li><strong>Stale Knowledge:</strong> Training data frozen at cutoff.</li>
<li><strong>Hallucinations:</strong> Fabricated but fluent statements.</li>
<li><strong>Bias:</strong> Inherited from source data distributions.</li>
<li><strong>Non-Determinism:</strong> Sampling randomness affects reproducibility.</li>
</ul>
</div>
</div>
<div class="section" id="prompt-engineering-defined">
<h2 id="prompt-engineering-defined"><span class="me-2">Prompt Engineering Defined</span><a href="#prompt-engineering-defined" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="formal-definition">
<h3 id="formal-definition"><span class="me-2">Formal Definition</span><a href="#formal-definition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Prompt Engineering (PE)</strong> is the systematic design of model inputs—prompts—to achieve desired output behaviors from language models.</p>
<p><strong>It involves</strong>
- Understanding model behavior and limitations.</p>
<ul class="simple">
<li>Framing questions or tasks effectively.</li>
<li>Specifying structure, tone, or reasoning depth.</li>
<li>Iteratively refining for performance and control.</li>
</ul>
</div>
<div class="section" id="historical-context">
<h3 id="historical-context"><span class="me-2">Historical Context</span><a href="#historical-context" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="44%" />
<col width="56%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Era</th>
<th class="head">Milestone</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Pre-Transformer (2017)</strong></td>
<td>Word2Vec, Seq2Seq; prompts were rigid.</td>
</tr>
<tr><td><strong>Transformer Revolution (2017)</strong></td>
<td>“Attention Is All You Need” introduced self-attention.</td>
</tr>
<tr><td><strong>GPT Series (2018 → present)</strong></td>
<td>Prompting becomes human-readable instruction interface.</td>
</tr>
<tr><td><strong>Instruction Tuning &amp; RLHF</strong></td>
<td>Models learn to follow natural-language directives.</td>
</tr>
<tr><td><strong>Prompt Engineering as a Skill (2022 →)</strong></td>
<td>Emerged as critical interface discipline.</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div class="section" id="anatomy-of-a-prompt">
<h2 id="anatomy-of-a-prompt"><span class="me-2">Anatomy of a Prompt</span><a href="#anatomy-of-a-prompt" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>A robust prompt combines <strong>role, instruction, context, examples,</strong> and <strong>formatting constraints</strong>.</p>
<div class="section" id="general-template">
<h3 id="general-template"><span class="me-2">General Template</span><a href="#general-template" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>[Role/Persona]
</span><span class="line">[Task Instruction]
</span><span class="line">[Context/Background]
</span><span class="line">[Input Examples (optional)]
</span><span class="line">[Output Format Specification]
</span></code></pre></td></tr></table></div></div></figure></div>
<div class="section" id="example">
<h3 id="example"><span class="me-2">Example</span><a href="#example" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>You are an experienced travel consultant.
</span><span class="line">Task: Design a 3-day itinerary for Kyoto emphasizing historical sites.
</span><span class="line">Include travel time estimates and dining suggestions.
</span><span class="line">Present results as a markdown table.
</span></code></pre></td></tr></table></div></div></figure><p>→ The role primes behavior; task defines scope; context narrows relevance; format ensures consistency.</p>
</div>
</div>
<div class="section" id="prompt-categories">
<h2 id="prompt-categories"><span class="me-2">Prompt Categories</span><a href="#prompt-categories" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="28%" />
<col width="44%" />
<col width="29%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Category</th>
<th class="head">Description</th>
<th class="head">Typical Use</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Descriptive Prompt</strong></td>
<td>Request explanation or information.</td>
<td>Q&amp;A, definitions</td>
</tr>
<tr><td><strong>Directive Prompt</strong></td>
<td>Instruct model to perform an action.</td>
<td>Summaries, translations</td>
</tr>
<tr><td><strong>Comparative Prompt</strong></td>
<td>Ask for evaluation between options.</td>
<td>Decision support</td>
</tr>
<tr><td><strong>Creative Prompt</strong></td>
<td>Stimulate original composition.</td>
<td>Story generation</td>
</tr>
<tr><td><strong>Analytical Prompt</strong></td>
<td>Require reasoning or calculation.</td>
<td>Problem solving</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="llm-generation-controls">
<h2 id="llm-generation-controls"><span class="me-2">LLM Generation Controls</span><a href="#llm-generation-controls" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>The output distribution is shaped by several parameters</strong></p>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="30%" />
<col width="30%" />
<col width="39%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Parameter</th>
<th class="head">Function</th>
<th class="head">Effect of Higher Value</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Temperature</strong></td>
<td>Sampling randomness</td>
<td>More creative, less stable</td>
</tr>
<tr><td><strong>Top-p (nucleus)</strong></td>
<td>Probability cutoff</td>
<td>Wider token sampling</td>
</tr>
<tr><td><strong>Max tokens</strong></td>
<td>Output length limit</td>
<td>Longer responses</td>
</tr>
<tr><td><strong>Frequency penalty</strong></td>
<td>Discourage repetition</td>
<td>More lexical diversity</td>
</tr>
<tr><td><strong>Presence penalty</strong></td>
<td>Encourage topic shift</td>
<td>Broader topic coverage</td>
</tr>
</tbody>
</table></div>
<div class="section" id="mathematical-note">
<h3 id="mathematical-note"><span class="me-2">Mathematical Note</span><a href="#mathematical-note" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Sampling draws next token *t* such that</strong></p>
<div class="math">
\begin{equation*}
t \sim \text{softmax}\!\left(\frac{\text{logits}}{T}\right)
\end{equation*}
</div>
<p>where <span class="math">\(T\)</span> is the temperature. Lower <em>T</em> → sharper probability peaks (deterministic).</p>
</div>
</div>
<div class="section" id="evaluation-and-prompt-iteration">
<h2 id="evaluation-and-prompt-iteration"><span class="me-2">Evaluation and Prompt Iteration</span><a href="#evaluation-and-prompt-iteration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering is iterative.
<strong>Cycle</strong></p>
<ol class="arabic simple">
<li><strong>Design Prompt</strong> – define goal and constraints.</li>
<li><strong>Generate Output</strong> – obtain model response.</li>
<li><strong>Evaluate</strong> – assess relevance, accuracy, tone.</li>
<li><strong>Refine</strong> – adjust wording, order, or explicitness.</li>
<li><strong>Automate Testing</strong> – create evaluation datasets.</li>
</ol>
<div class="section" id="heuristic-principles">
<h3 id="heuristic-principles"><span class="me-2">Heuristic Principles</span><a href="#heuristic-principles" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Specificity &gt; Vagueness.</li>
<li>Context &gt; Assumption.</li>
<li>Constraints guide style and format.</li>
<li>Step-by-step reasoning reduces error.</li>
<li>Examples anchor model behavior.</li>
</ul>
</div>
<div class="section" id="common-failure-modes">
<h3 id="common-failure-modes"><span class="me-2">Common Failure Modes</span><a href="#common-failure-modes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="30%" />
<col width="31%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Problem</th>
<th class="head">Example</th>
<th class="head">Remedy</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Ambiguous instruction</strong></td>
<td>“Summarize this.”</td>
<td>Specify length, tone, and audience.</td>
</tr>
<tr><td><strong>Overloaded context</strong></td>
<td>Too many topics.</td>
<td>Use prompt chaining.</td>
</tr>
<tr><td><strong>Missing role definition</strong></td>
<td>No persona → generic output.</td>
<td>Add “Act as …” clause.</td>
</tr>
<tr><td><strong>Under-specified format</strong></td>
<td>Messy lists.</td>
<td>Demand structured format (e.g. JSON).</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="best-practice-checklist">
<h3 id="best-practice-checklist"><span class="me-2">Best-Practice Checklist</span><a href="#best-practice-checklist" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Always declare <strong>purpose</strong> and <strong>audience</strong>.</li>
<li>Use <strong>few-shot examples</strong> to steer tone.</li>
<li>Control <strong>temperature and top-p</strong> explicitly.</li>
<li>Explicitly state <strong>format</strong> (e.g., tables).</li>
<li>Include <strong>verification steps</strong> in complex tasks.</li>
<li>Document each iteration for traceability.</li>
</ul>
</div>
</div>
<div class="section" id="transition-to-advanced-concepts">
<h2 id="transition-to-advanced-concepts"><span class="me-2">Transition to Advanced Concepts</span><a href="#transition-to-advanced-concepts" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Understanding these foundations enables construction of complex prompt systems.
The next part will cover <strong>advanced prompting techniques</strong>, including reasoning, multi-step workflows, retrieval integration, and self-reflection mechanisms.</p>
</div>
<div class="section" id="part-2-prompting-techniques-and-strategies">
<h2 id="part-2-prompting-techniques-and-strategies"><span class="me-2">Part 2 – Prompting Techniques and Strategies</span><a href="#part-2-prompting-techniques-and-strategies" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>
<div class="section" id="overview">
<h2 id="overview"><span class="me-2">Overview</span><a href="#overview" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompting strategies evolve from simple directives into structured reasoning frameworks.
The sophistication of a prompt determines not only <em>what</em> an LLM answers but <em>how</em> it reasons.
Techniques vary by objective — precision, creativity, factual grounding, or logical consistency.</p>
</div>
<div class="section" id="classification-of-prompting-techniques">
<h2 id="classification-of-prompting-techniques"><span class="me-2">Classification of Prompting Techniques</span><a href="#classification-of-prompting-techniques" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>Prompting methods can be categorized into</strong></p>
<ol class="arabic simple">
<li><strong>Example-based prompting</strong> — uses examples to shape behavior.</li>
<li><strong>Reasoning-based prompting</strong> — induces structured thinking.</li>
<li><strong>External-knowledge prompting</strong> — retrieves data beyond training.</li>
<li><strong>Meta-cognitive prompting</strong> — encourages self-evaluation and improvement.</li>
</ol>
<p>Each method balances control, cost, and interpretability.</p>
</div>
<div class="section" id="zero-shot-prompting">
<h2 id="zero-shot-prompting"><span class="me-2">Zero-shot Prompting</span><a href="#zero-shot-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id1">
<h3 id="id1"><span class="me-2">Definition</span><a href="#id1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A direct instruction without prior examples.
The model relies entirely on internal knowledge to complete the task.</p>
</div>
<div class="section" id="mechanism">
<h3 id="mechanism"><span class="me-2">Mechanism</span><a href="#mechanism" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>The prompt forms a conditional distribution over the task type.
Works best for factual or definitional queries where model priors are sufficient.</p>
</div>
<div class="section" id="id2">
<h3 id="id2"><span class="me-2">Example</span><a href="#id2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Translate the following sentence into French:
</span><span class="line">&quot;Knowledge is power.&quot;
</span></code></pre></td></tr></table></div></div></figure><p>→ Output: <em>Le savoir est le pouvoir.</em></p>
</div>
<div class="section" id="strengths">
<h3 id="strengths"><span class="me-2">Strengths</span><a href="#strengths" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Simplicity and speed.</li>
<li>Works well for general-purpose models.</li>
<li>Baseline for comparing other strategies.</li>
</ul>
</div>
<div class="section" id="limitations">
<h3 id="limitations"><span class="me-2">Limitations</span><a href="#limitations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>High variability on nuanced tasks.</li>
<li>Lacks stylistic control or domain adaptation.</li>
</ul>
</div>
</div>
<div class="section" id="few-shot-prompting">
<h2 id="few-shot-prompting"><span class="me-2">Few-shot Prompting</span><a href="#few-shot-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id3">
<h3 id="id3"><span class="me-2">Definition</span><a href="#id3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Provides <strong>examples of input–output pairs</strong> before requesting a new result.
The model infers pattern, structure, and style through contextual learning.</p>
</div>
<div class="section" id="id4">
<h3 id="id4"><span class="me-2">Example</span><a href="#id4" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>English → Spanish
</span><span class="line">cat → gato
</span><span class="line">house → casa
</span><span class="line">tree → ?
</span></code></pre></td></tr></table></div></div></figure><p>→ Output: <em>árbol</em></p>
</div>
<div class="section" id="id5">
<h3 id="id5"><span class="me-2">Mechanism</span><a href="#id5" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Implicitly fine-tunes model behavior within prompt context.
Effective because transformer attention captures in-context relationships.</p>
</div>
<div class="section" id="when-to-use">
<h3 id="when-to-use"><span class="me-2">When to Use</span><a href="#when-to-use" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Translation or classification tasks.</li>
<li>Style imitation (tone, formatting).</li>
<li>Domain adaptation without retraining.</li>
</ul>
</div>
<div class="section" id="design-considerations">
<h3 id="design-considerations"><span class="me-2">Design Considerations</span><a href="#design-considerations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Keep examples consistent in syntax.</li>
<li>Provide diverse coverage of patterns.</li>
<li>End examples with clear delimiter before new input.</li>
</ul>
</div>
</div>
<div class="section" id="chain-of-thought-cot-prompting">
<h2 id="chain-of-thought-cot-prompting"><span class="me-2">Chain-of-Thought (CoT) Prompting</span><a href="#chain-of-thought-cot-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id6">
<h3 id="id6"><span class="me-2">Definition</span><a href="#id6" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Encourages the model to <strong>reason step by step</strong> rather than jump to conclusions.
Introduced in <em>Wei et al., 2022 (“Chain-of-Thought Prompting Elicits Reasoning in Large Language Models”)</em>.</p>
</div>
<div class="section" id="id7">
<h3 id="id7"><span class="me-2">Example</span><a href="#id7" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Q: Tom has 3 apples. He buys 2 more. How many apples now?
</span><span class="line">A: Let&#39;s think step by step.
</span><span class="line">Tom starts with 3, buys 2 → total 5.
</span></code></pre></td></tr></table></div></div></figure></div>
<div class="section" id="id8">
<h3 id="id8"><span class="me-2">Mechanism</span><a href="#id8" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>By requesting reasoning steps, the model exposes intermediate latent reasoning paths.
This reduces logical omissions and improves numerical or causal inference.</p>
</div>
<div class="section" id="advantages">
<h3 id="advantages"><span class="me-2">Advantages</span><a href="#advantages" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Enhances interpretability.</li>
<li>Reduces reasoning errors in math, logic, and planning.</li>
<li>Enables post-hoc verification of intermediate steps.</li>
</ul>
</div>
<div class="section" id="variants">
<h3 id="variants"><span class="me-2">Variants</span><a href="#variants" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>Explicit CoT:</strong> Prompt includes “Let’s think step by step.”</li>
<li><strong>Implicit CoT:</strong> Model generates reasoning spontaneously (tuned behavior).</li>
<li><strong>Scratchpad CoT:</strong> Use structured fields (Reasoning:, Answer:) to isolate computation.</li>
</ul>
</div>
<div class="section" id="best-practice">
<h3 id="best-practice"><span class="me-2">Best Practice</span><a href="#best-practice" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Include explicit reasoning markers.
Avoid requesting CoT for trivial tasks to save compute.</p>
</div>
</div>
<div class="section" id="self-consistency-prompting">
<h2 id="self-consistency-prompting"><span class="me-2">Self-Consistency Prompting</span><a href="#self-consistency-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id9">
<h3 id="id9"><span class="me-2">Definition</span><a href="#id9" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>An extension of Chain-of-Thought prompting where multiple reasoning paths are sampled,
and the most consistent or frequent answer is selected.</p>
<p>Introduced by <em>Wang et al., 2022 (“Self-Consistency Improves Chain of Thought Reasoning in Language Models”)</em>.</p>
</div>
<div class="section" id="id10">
<h3 id="id10"><span class="me-2">Mechanism</span><a href="#id10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li>Sample several independent reasoning chains with different seeds.</li>
<li>Collect all final answers.</li>
<li>Choose the mode (most common) or highest-confidence answer.</li>
</ol>
<p><strong>Mathematically</strong></p>
<div class="math">
\begin{equation*}
\hat{y} = \text{mode}\{f(x, z_i)\}_{i=1}^n
\end{equation*}
</div>
<p>where <span class="math">\(z_i\)</span> are random seeds controlling generation diversity.</p>
</div>
<div class="section" id="benefits">
<h3 id="benefits"><span class="me-2">Benefits</span><a href="#benefits" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Increases reasoning reliability.</li>
<li>Reduces stochastic hallucination.</li>
<li>Adds ensemble-like stability to outputs.</li>
</ul>
</div>
<div class="section" id="trade-offs">
<h3 id="trade-offs"><span class="me-2">Trade-offs</span><a href="#trade-offs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Increased compute cost (multiple samples).</li>
<li>Requires automated aggregation pipeline.</li>
</ul>
</div>
</div>
<div class="section" id="prompt-chaining">
<h2 id="prompt-chaining"><span class="me-2">Prompt Chaining</span><a href="#prompt-chaining" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id11">
<h3 id="id11"><span class="me-2">Definition</span><a href="#id11" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Decomposes a complex task into a <strong>series of simpler prompts</strong> executed sequentially.
Each output becomes input for the next stage.</p>
</div>
<div class="section" id="process">
<h3 id="process"><span class="me-2">Process</span><a href="#process" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li><strong>Decomposition:</strong> Split large task into logical sub-steps.</li>
<li><strong>Execution:</strong> Run each prompt sequentially.</li>
<li><strong>Integration:</strong> Aggregate partial outputs into final answer.</li>
</ol>
</div>
<div class="section" id="id12">
<h3 id="id12"><span class="me-2">Example</span><a href="#id12" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Step 1: Summarize the research article.
</span><span class="line">Step 2: Extract five key insights from the summary.
</span><span class="line">Step 3: Draft three exam questions based on those insights.
</span></code></pre></td></tr></table></div></div></figure></div>
<div class="section" id="applications">
<h3 id="applications"><span class="me-2">Applications</span><a href="#applications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Summarization pipelines.</li>
<li>Multi-stage reasoning or document QA.</li>
<li>Workflow orchestration for automation agents.</li>
</ul>
</div>
<div class="section" id="id13">
<h3 id="id13"><span class="me-2">Advantages</span><a href="#id13" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Improves modularity and interpretability.</li>
<li>Allows re-use of intermediate artifacts.</li>
<li>Simplifies debugging of long tasks.</li>
</ul>
</div>
</div>
<div class="section" id="tree-of-thought-tot-prompting">
<h2 id="tree-of-thought-tot-prompting"><span class="me-2">Tree-of-Thought (ToT) Prompting</span><a href="#tree-of-thought-tot-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id14">
<h3 id="id14"><span class="me-2">Definition</span><a href="#id14" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A structured reasoning approach where the model <strong>explores multiple reasoning branches</strong>,
evaluates them, and selects the best path.</p>
<p>Inspired by search algorithms such as <strong>Monte Carlo Tree Search (MCTS)</strong>.</p>
</div>
<div class="section" id="id15">
<h3 id="id15"><span class="me-2">Mechanism</span><a href="#id15" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li>Generate multiple partial reasoning paths.</li>
<li>Evaluate each branch using internal or external heuristics.</li>
<li>Prune suboptimal branches.</li>
<li>Continue expanding promising directions.</li>
</ol>
</div>
<div class="section" id="id16">
<h3 id="id16"><span class="me-2">Benefits</span><a href="#id16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Handles complex reasoning (planning, puzzles).</li>
<li>Balances exploration and exploitation.</li>
<li>Enables self-evaluation through intermediate scoring.</li>
</ul>
</div>
<div class="section" id="challenges">
<h3 id="challenges"><span class="me-2">Challenges</span><a href="#challenges" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>High computational cost.</li>
<li>Requires orchestration logic for branch management.</li>
<li>Difficult to visualize large reasoning trees.</li>
</ul>
</div>
</div>
<div class="section" id="retrieval-augmented-generation-rag">
<h2 id="retrieval-augmented-generation-rag"><span class="me-2">Retrieval-Augmented Generation (RAG)</span><a href="#retrieval-augmented-generation-rag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id17">
<h3 id="id17"><span class="me-2">Definition</span><a href="#id17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Combines LLM generation with <strong>external document retrieval</strong>.
Introduced to improve factual accuracy and domain specificity.</p>
</div>
<div class="section" id="architecture">
<h3 id="architecture"><span class="me-2">Architecture</span><a href="#architecture" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li><strong>Retriever:</strong> Searches vector database for relevant documents using embeddings.</li>
<li><strong>Reader (LLM):</strong> Incorporates retrieved context to answer the query.</li>
</ol>
<p><strong>Mathematically</strong></p>
<div class="math">
\begin{equation*}
y = f_{\text{LLM}}(x, \text{Retrieve}(x, D))
\end{equation*}
</div>
<p>where <span class="math">\(D\)</span> is external knowledge base.</p>
</div>
<div class="section" id="id18">
<h3 id="id18"><span class="me-2">Advantages</span><a href="#id18" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Reduces hallucination.</li>
<li>Enables up-to-date and domain-specific answers.</li>
<li>Supports explainability via citation of sources.</li>
</ul>
</div>
<div class="section" id="id19">
<h3 id="id19"><span class="me-2">Applications</span><a href="#id19" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Knowledge management systems.</li>
<li>Academic or legal document querying.</li>
<li>Customer support chatbots.</li>
</ul>
</div>
<div class="section" id="implementation-notes">
<h3 id="implementation-notes"><span class="me-2">Implementation Notes</span><a href="#implementation-notes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Use high-quality embedding models (e.g., OpenAI text-embedding-3-large).</li>
<li>Normalize documents before indexing.</li>
<li>Chunk long documents intelligently (~500–1,000 tokens).</li>
<li>Maintain retrieval–generation alignment through consistent vector space.</li>
</ul>
</div>
</div>
<div class="section" id="react-prompting">
<h2 id="react-prompting"><span class="me-2">ReAct Prompting</span><a href="#react-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id20">
<h3 id="id20"><span class="me-2">Definition</span><a href="#id20" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Reason + Act</strong>: A hybrid paradigm combining internal reasoning with external actions.
Introduced in <em>Yao et al., 2022 (“ReAct: Synergizing Reasoning and Acting in Language Models”)</em>.</p>
</div>
<div class="section" id="workflow">
<h3 id="workflow"><span class="me-2">Workflow</span><a href="#workflow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li>Model reasons about task and identifies next action.</li>
<li>Executes tool call (search, API, code).</li>
<li>Observes result and continues reasoning.</li>
<li>Produces final answer.</li>
</ol>
</div>
<div class="section" id="example-simplified">
<h3 id="example-simplified"><span class="me-2">Example (simplified)</span><a href="#example-simplified" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Question: What is the latest GDP growth rate of Japan?
</span><span class="line">Thought: I should search the web for Japan GDP 2024.
</span><span class="line">Action: Search(&quot;Japan GDP 2024 site:imf.org&quot;)
</span><span class="line">Observation: Found IMF report stating 1.3%.
</span><span class="line">Answer: Japan&#39;s GDP growth rate for 2024 is approximately 1.3%.
</span></code></pre></td></tr></table></div></div></figure></div>
<div class="section" id="id21">
<h3 id="id21"><span class="me-2">Advantages</span><a href="#id21" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Enables factual grounding and adaptability.</li>
<li>Integrates tool-use capabilities.</li>
<li>Supports agent-like autonomy.</li>
</ul>
</div>
<div class="section" id="requirements">
<h3 id="requirements"><span class="me-2">Requirements</span><a href="#requirements" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Sandbox execution environment.</li>
<li>Access to trusted APIs.</li>
<li>Logging for action traceability.</li>
</ul>
</div>
</div>
<div class="section" id="reflexion-prompting">
<h2 id="reflexion-prompting"><span class="me-2">Reflexion Prompting</span><a href="#reflexion-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id22">
<h3 id="id22"><span class="me-2">Definition</span><a href="#id22" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A meta-cognitive prompting framework where the model <strong>evaluates, critiques, and refines its own outputs</strong> iteratively.</p>
<p>Origin: <em>Shinn et al., 2023 (“Reflexion: Language Agents with Verbal Reinforcement Learning”)</em>
Mechanism: Combines reasoning feedback loops with memory.</p>
</div>
<div class="section" id="id23">
<h3 id="id23"><span class="me-2">Process</span><a href="#id23" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li>Generate initial answer.</li>
<li>Critique its correctness and quality.</li>
<li>Produce an improved version guided by critique.</li>
<li>Optionally repeat for convergence.</li>
</ol>
</div>
<div class="section" id="id24">
<h3 id="id24"><span class="me-2">Example</span><a href="#id24" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Task: Write Python code to sort a list.
</span><span class="line">Attempt 1: Uses inefficient bubble sort.
</span><span class="line">Reflection: “Can this be optimized?”
</span><span class="line">Revision: Implements Timsort or built-in sort().
</span></code></pre></td></tr></table></div></div></figure></div>
<div class="section" id="id25">
<h3 id="id25"><span class="me-2">Benefits</span><a href="#id25" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Continuous self-improvement.</li>
<li>Reduces logical and factual error.</li>
<li>Builds implicit long-term learning via feedback logs.</li>
</ul>
</div>
</div>
<div class="section" id="advanced-prompting-patterns">
<h2 id="advanced-prompting-patterns"><span class="me-2">Advanced Prompting Patterns</span><a href="#advanced-prompting-patterns" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="meta-prompting">
<h3 id="meta-prompting"><span class="me-2">Meta-Prompting</span><a href="#meta-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A <strong>meta-prompt</strong> defines <em>how</em> a model should handle future prompts — effectively setting behavioral policy.
Used to bootstrap consistent style, tone, or structure.</p>
</div>
<div class="section" id="id26">
<h3 id="id26"><span class="me-2">Example</span><a href="#id26" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Meta-Instruction:
</span><span class="line">“For every answer you give, include definitions, examples, and key takeaways at the end.”
</span></code></pre></td></tr></table></div></div></figure><p>This persists across multiple user queries until context resets.</p>
</div>
<div class="section" id="dynamic-prompting">
<h3 id="dynamic-prompting"><span class="me-2">Dynamic Prompting</span><a href="#dynamic-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Prompts constructed programmatically at runtime.
Used in tool-augmented systems or retrieval chains.</p>
<p><strong>Example (template)</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="n">template</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Summarize the document titled &#39;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&#39; in 200 words.&quot;</span>
</span></code></pre></td></tr></table></div></div></figure></div>
<div class="section" id="id27">
<h3 id="id27"><span class="me-2">Benefits</span><a href="#id27" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Enables automation.</li>
<li>Allows conditional prompt assembly.</li>
<li>Supports scalability in multi-user environments.</li>
</ul>
</div>
</div>
<div class="section" id="comparison-summary">
<h2 id="comparison-summary"><span class="me-2">Comparison Summary</span><a href="#comparison-summary" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="40%" />
<col width="37%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Technique</th>
<th class="head">Core Idea</th>
<th class="head">Typical Use Case</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Zero-shot</td>
<td>Direct task instruction</td>
<td>Quick general queries</td>
</tr>
<tr><td>Few-shot</td>
<td>Provide examples</td>
<td>Style imitation, classification</td>
</tr>
<tr><td>Chain-of-Thought</td>
<td>Step-by-step reasoning</td>
<td>Logic, math, planning</td>
</tr>
<tr><td>Self-Consistency</td>
<td>Aggregate multiple reasoning paths</td>
<td>Reliable reasoning</td>
</tr>
<tr><td>Prompt Chaining</td>
<td>Sequential task decomposition</td>
<td>Multi-step workflows</td>
</tr>
<tr><td>Tree-of-Thought</td>
<td>Explore multiple reasoning trees</td>
<td>Search, decision-making</td>
</tr>
<tr><td>RAG</td>
<td>Integrate external data</td>
<td>Factual Q&amp;A, enterprise search</td>
</tr>
<tr><td>ReAct</td>
<td>Combine reasoning and tool use</td>
<td>Agents, dynamic retrieval</td>
</tr>
<tr><td>Reflexion</td>
<td>Self-critique and refinement</td>
<td>Iterative improvement</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="transition-to-next-section">
<h2 id="transition-to-next-section"><span class="me-2">Transition to Next Section</span><a href="#transition-to-next-section" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>The strategies above enable controlled reasoning and external knowledge integration.
In the next part, we examine <strong>Reasoning LLMs and Test-Time Compute</strong>, where these prompting principles evolve into architectural capabilities that let models think longer and smarter, not just bigger.</p>
</div>
<div class="section" id="part-3-reasoning-llms-and-test-time-compute">
<h2 id="part-3-reasoning-llms-and-test-time-compute"><span class="me-2">Part 3 – Reasoning LLMs and Test-Time Compute</span><a href="#part-3-reasoning-llms-and-test-time-compute" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>
<div class="section" id="id28">
<h2 id="id28"><span class="me-2">Overview</span><a href="#id28" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Traditional model improvement relied on scaling parameters, data, and compute during training.
However, this approach shows diminishing returns beyond trillion-parameter regimes.
The new frontier is <strong>reasoning efficiency</strong> — increasing capability at inference without enlarging the model itself.</p>
</div>
<div class="section" id="reasoning-llms">
<h2 id="reasoning-llms"><span class="me-2">Reasoning LLMs</span><a href="#reasoning-llms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id29">
<h3 id="id29"><span class="me-2">Definition</span><a href="#id29" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Reasoning LLMs</strong> are models explicitly designed to perform intermediate reasoning steps,
evaluate alternatives, and allocate additional computation at inference time.
They simulate deliberate thought rather than direct recall.</p>
</div>
<div class="section" id="contrast-with-conventional-llms">
<h3 id="contrast-with-conventional-llms"><span class="me-2">Contrast with Conventional LLMs</span><a href="#contrast-with-conventional-llms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="30%" />
<col width="28%" />
<col width="42%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Property</th>
<th class="head">Conventional LLM</th>
<th class="head">Reasoning LLM</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Compute focus</td>
<td>Training phase</td>
<td>Inference phase</td>
</tr>
<tr><td>Response generation</td>
<td>One-shot sampling</td>
<td>Multi-step deliberation</td>
</tr>
<tr><td>Output style</td>
<td>Fluent text</td>
<td>Structured reasoning</td>
</tr>
<tr><td>Evaluation</td>
<td>Perplexity</td>
<td>Process and outcome rewards</td>
</tr>
<tr><td>Typical examples</td>
<td>GPT-3, Claude 1</td>
<td>DeepSeek-R1, OpenAI o3-mini</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="scientific-basis">
<h3 id="scientific-basis"><span class="me-2">Scientific Basis</span><a href="#scientific-basis" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>The concept parallels the evolution from <strong>fast pattern recognition</strong> (System 1)
to <strong>deliberative reasoning</strong> (System 2) described in cognitive psychology.
By extending inference time, LLMs approximate deeper “thought loops.”</p>
</div>
</div>
<div class="section" id="train-time-compute-vs-test-time-compute">
<h2 id="train-time-compute-vs-test-time-compute"><span class="me-2">Train-Time Compute vs Test-Time Compute</span><a href="#train-time-compute-vs-test-time-compute" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="train-time-compute">
<h3 id="train-time-compute"><span class="me-2">Train-Time Compute</span><a href="#train-time-compute" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Compute used during pre-training or fine-tuning.
<strong>Follows empirical **scaling laws</strong> such as those proposed by Kaplan et al. (2020) and Chinchilla (2022)**</p>
<div class="math">
\begin{equation*}
L \propto N^{-a} D^{-b} C^{-c}
\end{equation*}
</div>
<p>where
<span class="math">\(L\)</span> = loss,
<span class="math">\(N\)</span> = model size,
<span class="math">\(D\)</span> = dataset size,
<span class="math">\(C\)</span> = compute budget.</p>
<p>Key insight: performance improves logarithmically; doubling compute yields sublinear gains.</p>
</div>
<div class="section" id="test-time-compute">
<h3 id="test-time-compute"><span class="me-2">Test-Time Compute</span><a href="#test-time-compute" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Compute consumed when the model answers a prompt.
Reasoning LLMs allocate variable inference effort — more steps, sampling paths, or evaluations — depending on task difficulty.</p>
<p><strong>Advantages</strong></p>
<ul class="simple">
<li><strong>Adaptive computation</strong>: hard problems receive more reasoning cycles.</li>
<li><strong>Energy efficiency</strong>: easy tasks terminate early.</li>
<li><strong>Scalable cognition</strong>: ability grows without retraining.</li>
</ul>
<p><strong>Mathematical abstraction</strong></p>
<div class="math">
\begin{equation*}
y = f(x, t), \quad t \in [t_{\min}, t_{\max}]
\end{equation*}
</div>
<p>where <span class="math">\(t\)</span> controls depth of reasoning (number of inference iterations).</p>
</div>
</div>
<div class="section" id="reasoning-path-sampling">
<h2 id="reasoning-path-sampling"><span class="me-2">Reasoning Path Sampling</span><a href="#reasoning-path-sampling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Most reasoning-oriented LLMs generate multiple partial solutions internally, then select or aggregate among them.</p>
<div class="section" id="approaches">
<h3 id="approaches"><span class="me-2">Approaches</span><a href="#approaches" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li><strong>Search Against Verifiers</strong> — generate candidate outputs, evaluate with reward models, choose best.</li>
<li><strong>Modify Proposal Distribution</strong> — alter token probabilities during generation to favor coherent reasoning chains.</li>
</ol>
</div>
<div class="section" id="typical-frameworks">
<h3 id="typical-frameworks"><span class="me-2">Typical Frameworks</span><a href="#typical-frameworks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>Self-Consistency</strong> (ensemble reasoning).</li>
<li><strong>Majority Voting</strong> among CoT runs.</li>
<li><strong>Best-of-N sampling</strong> guided by reward models.</li>
<li><strong>Backtracking</strong> where reasoning branches are pruned when inconsistent.</li>
</ul>
</div>
</div>
<div class="section" id="reward-models-for-reasoning">
<h2 id="reward-models-for-reasoning"><span class="me-2">Reward Models for Reasoning</span><a href="#reward-models-for-reasoning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="outcome-reward-model-orm">
<h3 id="outcome-reward-model-orm"><span class="me-2">Outcome Reward Model (ORM)</span><a href="#outcome-reward-model-orm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Evaluates <strong>final answer quality</strong> only.
Used in traditional reinforcement learning from human feedback (RLHF).</p>
</div>
<div class="section" id="process-reward-model-prm">
<h3 id="process-reward-model-prm"><span class="me-2">Process Reward Model (PRM)</span><a href="#process-reward-model-prm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Evaluates <strong>intermediate reasoning steps</strong> for correctness, coherence, or efficiency.
Encourages valid intermediate logic even if final answer differs slightly.</p>
</div>
<div class="section" id="comparison">
<h3 id="comparison"><span class="me-2">Comparison</span><a href="#comparison" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="34%" />
<col width="44%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Aspect</th>
<th class="head">ORM</th>
<th class="head">PRM</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Evaluation Unit</td>
<td>Final output</td>
<td>Intermediate steps</td>
</tr>
<tr><td>Feedback Signal</td>
<td>Binary or scalar reward</td>
<td>Step-wise dense feedback</td>
</tr>
<tr><td>Benefit</td>
<td>Simplicity</td>
<td>Better reasoning guidance</td>
</tr>
<tr><td>Limitation</td>
<td>Limited interpretability</td>
<td>Requires fine-grained annotation</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="combined-objective">
<h3 id="combined-objective"><span class="me-2">Combined Objective</span><a href="#combined-objective" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Some reasoning LLMs use both</strong></p>
<div class="math">
\begin{equation*}
R_{\text{total}} = \lambda_1 R_{\text{process}} + \lambda_2 R_{\text{outcome}}
\end{equation*}
</div>
<p>where <span class="math">\(\lambda\)</span> coefficients control emphasis.</p>
</div>
</div>
<div class="section" id="inference-time-scaling-techniques">
<h2 id="inference-time-scaling-techniques"><span class="me-2">Inference-Time Scaling Techniques</span><a href="#inference-time-scaling-techniques" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>These methods extend “thinking time” dynamically.</p>
<ol class="arabic simple">
<li><strong>Deliberate Decoding</strong>
- Model generates reasoning tokens, then final output tokens.<ul>
<li>Similar to CoT but embedded in architecture.</li>
</ul>
</li>
<li><strong>Speculative Sampling</strong>
- Produce draft completions quickly; verify or refine with larger model.</li>
<li><strong>Monte Carlo Reasoning</strong>
- Explore multiple reasoning paths; compute expectation over best candidates.</li>
<li><strong>Adaptive Computation Time (ACT)</strong>
- Decide dynamically how many transformer layers to evaluate per token.</li>
<li><strong>Verifier-Guided Search</strong>
- Use external evaluators to prune unsound paths in real time.</li>
</ol>
<p>Effectively, test-time compute substitutes for model size.</p>
</div>
<div class="section" id="architectural-innovations">
<h2 id="architectural-innovations"><span class="me-2">Architectural Innovations</span><a href="#architectural-innovations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="sparse-activation-models">
<h3 id="sparse-activation-models"><span class="me-2">Sparse Activation Models</span><a href="#sparse-activation-models" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Only a subset of neurons or experts activate per token, allowing deeper reasoning within fixed compute budgets.
Example: <strong>Mixture-of-Experts (MoE)</strong> architectures.</p>
</div>
<div class="section" id="scratchpad-buffers">
<h3 id="scratchpad-buffers"><span class="me-2">Scratchpad Buffers</span><a href="#scratchpad-buffers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Temporary token space where the model stores intermediate steps explicitly (e.g., “thinking” tokens).</p>
</div>
<div class="section" id="persistent-memory-augmentation">
<h3 id="persistent-memory-augmentation"><span class="me-2">Persistent Memory Augmentation</span><a href="#persistent-memory-augmentation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Extends context beyond window size using vector databases and retrieval pipelines.
Allows multi-session reasoning continuity.</p>
</div>
<div class="section" id="inner-monologue-paradigm">
<h3 id="inner-monologue-paradigm"><span class="me-2">Inner-Monologue Paradigm</span><a href="#inner-monologue-paradigm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>The model distinguishes between <strong>private reasoning tokens</strong> (not user-visible) and <strong>final communication tokens</strong>.
Enables internal self-dialogue and reasoning refinement.</p>
</div>
</div>
<div class="section" id="empirical-advances">
<h2 id="empirical-advances"><span class="me-2">Empirical Advances</span><a href="#empirical-advances" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="notable-reasoning-models">
<h3 id="notable-reasoning-models"><span class="me-2">Notable Reasoning Models</span><a href="#notable-reasoning-models" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="30%" />
<col width="23%" />
<col width="47%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Model</th>
<th class="head">Institution</th>
<th class="head">Key Feature</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>DeepSeek-R1</strong></td>
<td>DeepSeek (2025)</td>
<td>Explicit reasoning traces; test-time scaling.</td>
</tr>
<tr><td><strong>OpenAI o3-mini</strong></td>
<td>OpenAI (2025)</td>
<td>Small model optimized for structured reasoning.</td>
</tr>
<tr><td><strong>Gemini 2.0 Flash Thinking</strong></td>
<td>Google DeepMind (2025)</td>
<td>Adaptive inference depth; “thought” tokens.</td>
</tr>
<tr><td><strong>Anthropic Claude 3.5</strong></td>
<td>Anthropic (2024)</td>
<td>Constitutional alignment of reasoning steps.</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="performance-trends">
<h3 id="performance-trends"><span class="me-2">Performance Trends</span><a href="#performance-trends" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Reasoning LLMs outperform larger static models on logic benchmarks.</li>
<li>Gains saturate near 10× inference cost; beyond that diminishing returns reappear.</li>
<li>Hybrid reasoning + retrieval often yields best real-world performance.</li>
</ul>
</div>
</div>
<div class="section" id="evaluation-metrics-for-reasoning">
<h2 id="evaluation-metrics-for-reasoning"><span class="me-2">Evaluation Metrics for Reasoning</span><a href="#evaluation-metrics-for-reasoning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Traditional metrics (BLEU, ROUGE, accuracy) inadequately measure reasoning quality.
<strong>New measures include</strong></p>
<ul class="simple">
<li><strong>Step Accuracy:</strong> fraction of correct intermediate steps.</li>
<li><strong>Process Coherence:</strong> logical consistency across reasoning chain.</li>
<li><strong>Verifier-Score:</strong> reward model score on final or intermediate reasoning.</li>
<li><strong>Compute Efficiency:</strong> reasoning accuracy per unit of inference FLOPs.</li>
</ul>
<p><strong>Example workflow</strong></p>
<ol class="arabic simple">
<li>Generate N reasoning traces.</li>
<li>Score each trace using PRM.</li>
<li>Select trace with highest cumulative reward.</li>
</ol>
</div>
<div class="section" id="trade-offs-and-engineering-implications">
<h2 id="trade-offs-and-engineering-implications"><span class="me-2">Trade-offs and Engineering Implications</span><a href="#trade-offs-and-engineering-implications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id30">
<h3 id="id30"><span class="me-2">Advantages</span><a href="#id30" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Stronger logical reasoning and mathematical accuracy.</li>
<li>Modular scalability without retraining.</li>
<li>Transparent reasoning processes.</li>
</ul>
</div>
<div class="section" id="costs">
<h3 id="costs"><span class="me-2">Costs</span><a href="#costs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Higher inference latency.</li>
<li>Need for auxiliary verifiers and evaluators.</li>
<li>More complex orchestration pipelines.</li>
</ul>
</div>
<div class="section" id="design-heuristics">
<h3 id="design-heuristics"><span class="me-2">Design Heuristics</span><a href="#design-heuristics" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li>Use reasoning modes selectively (triggered by complexity estimation).</li>
<li>Cache reasoning results for repeated tasks.</li>
<li>Limit number of branches to balance cost vs. accuracy.</li>
<li>Train verifiers with diverse reasoning data.</li>
</ul>
</div>
</div>
<div class="section" id="conceptual-summary">
<h2 id="conceptual-summary"><span class="me-2">Conceptual Summary</span><a href="#conceptual-summary" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li><strong>Traditional scaling</strong> improved fluency through larger networks.</li>
<li><strong>Reasoning scaling</strong> improves intelligence by allocating variable compute.</li>
<li><strong>Reward models</strong> provide evaluative feedback for both outcome and process.</li>
<li><strong>Search and sampling</strong> strategies let LLMs simulate deliberate thought.</li>
<li><strong>Empirical evidence</strong> shows that reasoning LLMs can surpass models 5–10× their size when given more inference time.</li>
</ol>
</div>
<div class="section" id="id31">
<h2 id="id31"><span class="me-2">Transition to Next Section</span><a href="#id31" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Having examined how reasoning capacity emerges from architectural and computational advances,
the next section explores <strong>LLM Agents and Autonomy</strong> — systems that combine reasoning, memory, and tool use to achieve complex real-world goals.</p>
</div>
<div class="section" id="part-4-llm-agents-autonomy-and-system-integration">
<h2 id="part-4-llm-agents-autonomy-and-system-integration"><span class="me-2">Part 4 – LLM Agents, Autonomy, and System Integration</span><a href="#part-4-llm-agents-autonomy-and-system-integration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>
<div class="section" id="id32">
<h2 id="id32"><span class="me-2">Overview</span><a href="#id32" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Reasoning alone is insufficient for real-world competence.
To perform multi-step tasks, integrate information, and act on environments,
LLMs must operate as <strong>agents</strong> — autonomous systems capable of perception, reasoning, planning, and execution.</p>
</div>
<div class="section" id="definition-of-an-llm-agent">
<h2 id="definition-of-an-llm-agent"><span class="me-2">Definition of an LLM Agent</span><a href="#definition-of-an-llm-agent" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>An <strong>LLM agent</strong> is a system where a large language model acts as the <strong>cognitive core</strong>,
interfacing with external tools, memory stores, and APIs to perform complex, goal-oriented tasks.</p>
<p><strong>Conceptually</strong></p>
<div class="math">
\begin{equation*}
\text{Agent} = \{ LLM, \text{Tools}, \text{Memory}, \text{Planner}, \text{Environment} \}
\end{equation*}
</div>
<p>Each component plays a distinct functional role.</p>
</div>
<div class="section" id="core-architecture">
<h2 id="core-architecture"><span class="me-2">Core Architecture</span><a href="#core-architecture" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li><strong>LLM Core</strong>
- Performs reasoning, planning, and natural language understanding.<ul>
<li>Generates intermediate plans or decisions in text.</li>
</ul>
</li>
<li><strong>Memory Module</strong>
- Stores long-term or session-specific context.<ul>
<li>Implemented via vector databases, JSON stores, or key–value caches.</li>
</ul>
</li>
<li><strong>Tool Interface</strong>
- Allows external function calls (e.g., search, code execution, file operations).<ul>
<li>Extends beyond textual reasoning into concrete actions.</li>
</ul>
</li>
<li><strong>Planner / Controller</strong>
- Manages decision loops and subgoal scheduling.<ul>
<li>Uses techniques from symbolic AI and reinforcement learning.</li>
</ul>
</li>
<li><strong>Environment</strong>
- Represents the external world (e.g., API endpoints, OS shell, web).</li>
</ol>
</div>
<div class="section" id="agentic-loop">
<h2 id="agentic-loop"><span class="me-2">Agentic Loop</span><a href="#agentic-loop" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>General execution cycle</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>1. Perceive → 2. Plan → 3. Act → 4. Observe → 5. Reflect → Repeat
</span></code></pre></td></tr></table></div></div></figure><p><strong>Perceive:</strong> interpret input or new environment state.
<strong>Plan:</strong> decide sequence of actions to achieve goal.
<strong>Act:</strong> execute tools or emit messages.
<strong>Observe:</strong> read feedback or results.
<strong>Reflect:</strong> update internal state, memory, or strategy.</p>
<div class="section" id="id33">
<h3 id="id33"><span class="me-2">Variants</span><a href="#id33" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>ReAct</strong> (Reason + Act): interleaves reasoning traces with tool calls.</li>
<li><strong>Reflexion:</strong> integrates self-evaluation feedback loops.</li>
<li><strong>AutoGPT-style agents:</strong> perform goal decomposition recursively.</li>
</ul>
</div>
</div>
<div class="section" id="reasoning-acting-the-react-paradigm">
<h2 id="reasoning-acting-the-react-paradigm"><span class="me-2">Reasoning + Acting: The ReAct Paradigm</span><a href="#reasoning-acting-the-react-paradigm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>The <strong>ReAct</strong> framework (Yao et al., 2022) merges <em>reasoning traces</em> with <em>actions</em> in one prompt chain.</p>
<p><strong>Example pattern</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Thought: I need to find the latest sales data.
</span><span class="line">Action: search(&quot;latest 2025 sales report&quot;)
</span><span class="line">Observation: Found CSV file.
</span><span class="line">Thought: I should summarize the results.
</span><span class="line">Action: python(&quot;summarize_sales(&#39;sales_2025.csv&#39;)&quot;)
</span></code></pre></td></tr></table></div></div></figure><p>The model alternates between “thought” and “action” tokens.
This design grounds reasoning in verifiable, tool-mediated results.</p>
<p><strong>Advantages</strong></p>
<ul class="simple">
<li>Prevents hallucination through factual grounding.</li>
<li>Enables multi-step workflows.</li>
<li>Supports transparency (trace inspection).</li>
</ul>
</div>
<div class="section" id="memory-systems">
<h2 id="memory-systems"><span class="me-2">Memory Systems</span><a href="#memory-systems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Memory is crucial for persistent intelligence.
It enables agents to recall facts, user preferences, and previous results.</p>
<div class="section" id="types-of-memory">
<h3 id="types-of-memory"><span class="me-2">Types of Memory</span><a href="#types-of-memory" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="28%" />
<col width="23%" />
<col width="21%" />
<col width="28%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Type</th>
<th class="head">Duration</th>
<th class="head">Implementation</th>
<th class="head">Use</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Short-term (context)</strong></td>
<td>Current session</td>
<td>Token window</td>
<td>Holds local dialogue</td>
</tr>
<tr><td><strong>Episodic</strong></td>
<td>Across sessions</td>
<td>Vector embeddings</td>
<td>Stores experience traces</td>
</tr>
<tr><td><strong>Semantic</strong></td>
<td>Long-term knowledge</td>
<td>Databases / KBs</td>
<td>Domain expertise</td>
</tr>
<tr><td><strong>Procedural</strong></td>
<td>Task workflows</td>
<td>YAML / scripts</td>
<td>Automation logic</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="memory-management">
<h3 id="memory-management"><span class="me-2">Memory Management</span><a href="#memory-management" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>Compression:</strong> summarize to save context length.</li>
<li><strong>Retrieval:</strong> cosine similarity search for relevance.</li>
<li><strong>Prioritization:</strong> weight by recency or frequency.</li>
<li><strong>Forgetting:</strong> prune outdated or irrelevant entries.</li>
</ul>
</div>
<div class="section" id="id34">
<h3 id="id34"><span class="me-2">Retrieval-Augmented Generation (RAG)</span><a href="#id34" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Pipeline</strong></p>
<ol class="arabic simple">
<li>Encode user query → embedding vector.</li>
<li>Retrieve relevant documents from vector store.</li>
<li>Inject retrieved text into model prompt.</li>
<li>Generate final response conditioned on retrieved data.</li>
</ol>
<p>This approach extends model knowledge dynamically without retraining.</p>
</div>
</div>
<div class="section" id="tool-use-and-function-calling">
<h2 id="tool-use-and-function-calling"><span class="me-2">Tool Use and Function Calling</span><a href="#tool-use-and-function-calling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>LLMs interact with external systems through <strong>function calling APIs</strong>.</p>
<p><strong>Pattern</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="json"><span class="line"><span></span><span class="p">{</span>
</span><span class="line">
</span><span class="line">  <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;search_database&quot;</span><span class="p">,</span>
</span><span class="line">  <span class="nt">&quot;arguments&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;market trends 2025&quot;</span> <span class="p">}</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></div></figure><p>After executing the call, the result is returned to the LLM, forming a reasoning–action feedback loop.</p>
<p><strong>Tool types include</strong></p>
<ul class="simple">
<li><strong>Search engines</strong> (retrieval).</li>
<li><strong>Calculators / Code interpreters</strong>.</li>
<li><strong>Database connectors</strong>.</li>
<li><strong>Scheduling systems</strong>.</li>
<li><strong>APIs for external services (email, docs, etc.)</strong>.</li>
</ul>
<p><strong>Tool selection strategies</strong></p>
<ul class="simple">
<li><strong>Static mapping</strong>: predefined tool per query type.</li>
<li><strong>Dynamic routing</strong>: LLM decides best tool based on context.</li>
</ul>
</div>
<div class="section" id="autonomy-levels">
<h2 id="autonomy-levels"><span class="me-2">Autonomy Levels</span><a href="#autonomy-levels" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>LLM agents vary in autonomy according to how much decision-making they control.</p>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="44%" />
<col width="31%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Level</th>
<th class="head">Description</th>
<th class="head">Example</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>0 – Reactive</strong></td>
<td>Responds only to direct prompts.</td>
<td>Chatbot</td>
</tr>
<tr><td><strong>1 – Contextual</strong></td>
<td>Uses short-term memory, no planning.</td>
<td>Customer assistant</td>
</tr>
<tr><td><strong>2 – Planning</strong></td>
<td>Decomposes goals, executes actions.</td>
<td>AutoGPT</td>
</tr>
<tr><td><strong>3 – Reflective</strong></td>
<td>Self-evaluates and adjusts strategy.</td>
<td>Reflexion agent</td>
</tr>
<tr><td><strong>4 – Meta-agentic</strong></td>
<td>Coordinates multiple sub-agents.</td>
<td>Multi-agent orchestration</td>
</tr>
</tbody>
</table></div>
<p>The higher the autonomy, the greater the need for safety controls and performance monitoring.</p>
</div>
<div class="section" id="reflection-and-self-improvement">
<h2 id="reflection-and-self-improvement"><span class="me-2">Reflection and Self-Improvement</span><a href="#reflection-and-self-improvement" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Agents can use feedback loops to refine reasoning and output quality.</p>
<p><strong>Typical steps</strong></p>
<ol class="arabic simple">
<li><strong>Generate</strong> initial answer.</li>
<li><strong>Critique</strong> output against goal and criteria.</li>
<li><strong>Revise</strong> with incorporated feedback.</li>
<li><strong>Evaluate</strong> improvement.</li>
</ol>
<p>Frameworks such as <em>Reflexion</em> and <em>Self-Refine</em> automate this cycle.</p>
<p><strong>Mathematical abstraction</strong></p>
<div class="math">
\begin{equation*}
y_{t+1} = f(y_t, \text{feedback}(y_t))
\end{equation*}
</div>
<p>Iterative convergence approximates self-improvement.</p>
</div>
<div class="section" id="multi-agent-systems">
<h2 id="multi-agent-systems"><span class="me-2">Multi-Agent Systems</span><a href="#multi-agent-systems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="concept">
<h3 id="concept"><span class="me-2">Concept</span><a href="#concept" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Multiple LLM agents cooperate or compete to achieve complex goals.
They may specialize by role: planner, researcher, critic, executor.</p>
</div>
<div class="section" id="coordination-models">
<h3 id="coordination-models"><span class="me-2">Coordination Models</span><a href="#coordination-models" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>Hierarchical control</strong>: one supervisor assigns sub-tasks.</li>
<li><strong>Decentralized consensus</strong>: peer voting among agents.</li>
<li><strong>Market-based scheduling</strong>: tasks allocated by simulated bidding.</li>
</ul>
<p><strong>Benefits</strong></p>
<ul class="simple">
<li>Parallelized reasoning.</li>
<li>Error correction through redundancy.</li>
<li>Division of labor (domain specialization).</li>
</ul>
<p><strong>Risks</strong></p>
<ul class="simple">
<li>Cascading hallucinations.</li>
<li>Excessive token cost.</li>
<li>Coordination failures.</li>
</ul>
</div>
</div>
<div class="section" id="safety-and-control-mechanisms">
<h2 id="safety-and-control-mechanisms"><span class="me-2">Safety and Control Mechanisms</span><a href="#safety-and-control-mechanisms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Autonomous systems require safeguards to prevent unintended behavior.</p>
<p><strong>Key dimensions</strong></p>
<ul class="simple">
<li><strong>Goal alignment:</strong> constrain objectives with predefined rules.</li>
<li><strong>Rate limiting:</strong> cap inference loops to prevent runaway cost.</li>
<li><strong>Validation layers:</strong> verify outputs via deterministic tools.</li>
<li><strong>Human-in-the-loop:</strong> require confirmation for critical actions.</li>
<li><strong>Sandboxing:</strong> isolate execution environments for safety.</li>
</ul>
<div class="section" id="alignment-via-constitutional-ai">
<h3 id="alignment-via-constitutional-ai"><span class="me-2">Alignment via Constitutional AI</span><a href="#alignment-via-constitutional-ai" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Constitutional AI (Anthropic) defines explicit principles guiding agent behavior.
Instead of relying solely on human labels, the agent critiques its own output based on written rules.</p>
<p><strong>Example principles</strong></p>
<ul class="simple">
<li>Be helpful, harmless, and honest.</li>
<li>Respect privacy and autonomy.</li>
<li>Prioritize factual accuracy.</li>
</ul>
</div>
</div>
<div class="section" id="metrics-for-agent-evaluation">
<h2 id="metrics-for-agent-evaluation"><span class="me-2">Metrics for Agent Evaluation</span><a href="#metrics-for-agent-evaluation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="28%" />
<col width="49%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Category</th>
<th class="head">Metric</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Task Success</strong></td>
<td>Goal completion rate</td>
<td>% of successfully achieved objectives</td>
</tr>
<tr><td><strong>Efficiency</strong></td>
<td>Tokens per task</td>
<td>Computational cost</td>
</tr>
<tr><td><strong>Consistency</strong></td>
<td>Result variance</td>
<td>Stability across runs</td>
</tr>
<tr><td><strong>Safety</strong></td>
<td>Policy compliance</td>
<td>Adherence to alignment rules</td>
</tr>
<tr><td><strong>Adaptivity</strong></td>
<td>Generalization</td>
<td>Performance on novel inputs</td>
</tr>
</tbody>
</table></div>
<p>Experiment protocols often combine quantitative and qualitative review.</p>
</div>
<div class="section" id="integration-with-external-systems">
<h2 id="integration-with-external-systems"><span class="me-2">Integration with External Systems</span><a href="#integration-with-external-systems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>LLM agents can be embedded into operational stacks</strong></p>
<ul class="simple">
<li><strong>Enterprise workflows:</strong> document analysis, summarization, meeting assistance.</li>
<li><strong>Scientific discovery:</strong> hypothesis generation, data analysis.</li>
<li><strong>Software engineering:</strong> code generation and debugging pipelines.</li>
<li><strong>Robotics and IoT:</strong> natural-language control of sensors and actuators.</li>
<li><strong>Customer support automation:</strong> contextual reasoning across channels.</li>
</ul>
<div class="section" id="apis-and-frameworks">
<h3 id="apis-and-frameworks"><span class="me-2">APIs and Frameworks</span><a href="#apis-and-frameworks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul class="simple">
<li><strong>LangChain</strong> – modular prompt and tool orchestration.</li>
<li><strong>LlamaIndex</strong> – retrieval and context management.</li>
<li><strong>Semantic Kernel (Microsoft)</strong> – skill-based agent composition.</li>
<li><strong>CrewAI / AutoGen / Haystack</strong> – multi-agent experimentation.</li>
<li><strong>OpenAI Function Calling / JSON Mode</strong> – structured action execution.</li>
</ul>
</div>
</div>
<div class="section" id="emerging-research-directions">
<h2 id="emerging-research-directions"><span class="me-2">Emerging Research Directions</span><a href="#emerging-research-directions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li><strong>Meta-cognition</strong>
- Agents aware of their own uncertainty; can seek clarification.</li>
<li><strong>Goal learning</strong>
- Deriving abstract objectives from examples or human feedback.</li>
<li><strong>Continual learning</strong>
- Updating memory without catastrophic forgetting.</li>
<li><strong>Multi-modal perception</strong>
- Integrating vision, audio, and text reasoning.</li>
<li><strong>Distributed agent societies</strong>
- Coordinated swarms simulating organizational intelligence.</li>
</ol>
</div>
<div class="section" id="id35">
<h2 id="id35"><span class="me-2">Conceptual Summary</span><a href="#id35" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li>LLMs become <em>agents</em> when coupled with memory, tools, and planning logic.</li>
<li>ReAct and Reflexion frameworks ground reasoning in real-world actions.</li>
<li>Autonomy levels scale from reactive chatbots to self-improving planners.</li>
<li>Safety, evaluation, and control remain central to sustainable deployment.</li>
<li>Multi-agent systems foreshadow collective AI ecosystems capable of distributed reasoning.</li>
</ol>
</div>
<div class="section" id="id36">
<h2 id="id36"><span class="me-2">Transition to Next Section</span><a href="#id36" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Next: <strong>Part 5 – Advanced Prompt Design, Evaluation, and Human Alignment</strong>,
which unifies all prior principles into a practical methodology for expert-level prompt engineering and system optimization.</p>
</div>
<div class="section" id="part-5-advanced-prompt-design-evaluation-and-human-alignment">
<h2 id="part-5-advanced-prompt-design-evaluation-and-human-alignment"><span class="me-2">Part 5 – Advanced Prompt Design, Evaluation, and Human Alignment</span><a href="#part-5-advanced-prompt-design-evaluation-and-human-alignment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>
<div class="section" id="id37">
<h2 id="id37"><span class="me-2">Overview</span><a href="#id37" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>This section consolidates advanced-level knowledge for building robust prompt systems.
It addresses systematic prompt optimization, evaluation methodologies, human alignment, and emerging frontiers in automated reasoning control.</p>
</div>
<div class="section" id="prompt-design-as-a-systematic-process">
<h2 id="prompt-design-as-a-systematic-process"><span class="me-2">Prompt Design as a Systematic Process</span><a href="#prompt-design-as-a-systematic-process" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Effective prompting is not artistic improvisation; it is structured engineering.
An advanced prompt designer approaches every task as a <em>control problem</em> — how to guide probabilistic text generation toward a defined objective under constraints.</p>
<p><strong>The process consists of the following stages</strong></p>
<ol class="arabic simple">
<li><strong>Goal definition</strong>
- Clarify what constitutes success: factuality, style, reasoning depth, or novelty.</li>
<li><strong>Constraint modeling</strong>
- Define limits of tone, format, ethical boundaries, or domain scope.</li>
<li><strong>Prompt synthesis</strong>
- Construct structured templates incorporating examples and format instructions.</li>
<li><strong>Iterative optimization</strong>
- Measure, refine, and automate prompt improvement.</li>
<li><strong>Deployment</strong>
- Integrate optimized prompts into production workflows or agent architectures.</li>
</ol>
</div>
<div class="section" id="prompt-optimization-techniques">
<h2 id="prompt-optimization-techniques"><span class="me-2">Prompt Optimization Techniques</span><a href="#prompt-optimization-techniques" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="prompt-templates">
<h3 id="prompt-templates"><span class="me-2">Prompt Templates</span><a href="#prompt-templates" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Reusable skeletons with placeholders for variable data.</p>
<p><strong>Example</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Task: Summarize the following report for {audience}.
</span><span class="line">Constraints: Limit to {word_count} words, focus on {topics}.
</span><span class="line">Report: {document_text}
</span></code></pre></td></tr></table></div></div></figure><p>These templates enforce consistency across tasks and enable automation.</p>
</div>
<div class="section" id="id38">
<h3 id="id38"><span class="me-2">Prompt Chaining</span><a href="#id38" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Decompose complex objectives into multiple sequential sub-prompts.
Each stage feeds its output into the next.</p>
<p><strong>Example chain</strong></p>
<ol class="arabic simple">
<li>Extract keywords.</li>
<li>Retrieve background data.</li>
<li>Compose summary.</li>
<li>Verify factual accuracy.</li>
</ol>
<p><strong>Benefits</strong>
- Reduces context complexity.</p>
<ul class="simple">
<li>Enables modular testing.</li>
<li>Improves interpretability.</li>
</ul>
</div>
<div class="section" id="tree-of-thought-tot">
<h3 id="tree-of-thought-tot"><span class="me-2">Tree-of-Thought (ToT)</span><a href="#tree-of-thought-tot" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Generalizes Chain-of-Thought by exploring reasoning <em>branches</em> in parallel.
Each branch represents an alternative reasoning path, later evaluated for coherence and reward.</p>
<p><strong>ToT algorithm steps</strong></p>
<ol class="arabic simple">
<li>Generate multiple reasoning branches.</li>
<li>Evaluate partial conclusions using heuristic or learned scoring.</li>
<li>Expand promising branches.</li>
<li>Select highest-reward terminal node as output.</li>
</ol>
<p>Formally, ToT approximates best-first search through reasoning space.</p>
</div>
<div class="section" id="self-refinement-and-reflection-loops">
<h3 id="self-refinement-and-reflection-loops"><span class="me-2">Self-Refinement and Reflection Loops</span><a href="#self-refinement-and-reflection-loops" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A model critiques and edits its own output.</p>
<p><strong>Example pattern</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Step 1: Produce initial draft.
</span><span class="line">Step 2: Evaluate for clarity, correctness, and tone.
</span><span class="line">Step 3: Revise with improvements.
</span></code></pre></td></tr></table></div></div></figure><p>This meta-cognitive loop enhances reliability and coherence.</p>
</div>
<div class="section" id="automated-prompt-tuning-apt">
<h3 id="automated-prompt-tuning-apt"><span class="me-2">Automated Prompt Tuning (APT)</span><a href="#automated-prompt-tuning-apt" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Optimization of prompt parameters via algorithmic search rather than manual editing.</p>
<p><strong>Methods include</strong></p>
<ul class="simple">
<li><strong>Gradient-free optimization</strong> (e.g., evolutionary search).</li>
<li><strong>Reinforcement learning</strong> (prompt as policy).</li>
<li><strong>Bayesian optimization</strong> (evaluate expected improvement).</li>
</ul>
<p>APT uses quantitative metrics (accuracy, BLEU, reward) to guide search.</p>
</div>
<div class="section" id="soft-prompting">
<h3 id="soft-prompting"><span class="me-2">Soft Prompting</span><a href="#soft-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Instead of discrete text, prompts can exist as <strong>learned embeddings</strong> inserted into the model input.
Used in <strong>prompt tuning</strong> and <strong>prefix-tuning</strong> for fine-grained control.</p>
<p><strong>Mathematically</strong></p>
<div class="math">
\begin{equation*}
h' = [P_{\text{learned}}; h_{\text{text}}]
\end{equation*}
</div>
<p>where <span class="math">\(P_{\text{learned}}\)</span> is a trainable soft prompt vector.</p>
</div>
</div>
<div class="section" id="evaluation-frameworks">
<h2 id="evaluation-frameworks"><span class="me-2">Evaluation Frameworks</span><a href="#evaluation-frameworks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Evaluation is essential for moving from anecdotal to systematic improvement.</p>
<div class="section" id="dimensions-of-evaluation">
<h3 id="dimensions-of-evaluation"><span class="me-2">Dimensions of Evaluation</span><a href="#dimensions-of-evaluation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="49%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Dimension</th>
<th class="head">Description</th>
<th class="head">Metrics</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Accuracy</strong></td>
<td>Correctness of factual or logical claims.</td>
<td>BLEU, ROUGE, QA-F1</td>
</tr>
<tr><td><strong>Relevance</strong></td>
<td>Contextual alignment with user intent.</td>
<td>Semantic similarity</td>
</tr>
<tr><td><strong>Consistency</strong></td>
<td>Reproducibility across runs.</td>
<td>Variance analysis</td>
</tr>
<tr><td><strong>Readability</strong></td>
<td>Linguistic fluency and structure.</td>
<td>Grammar scores</td>
</tr>
<tr><td><strong>Ethical alignment</strong></td>
<td>Compliance with human values.</td>
<td>Safety audits</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="evaluation-pipelines">
<h3 id="evaluation-pipelines"><span class="me-2">Evaluation Pipelines</span><a href="#evaluation-pipelines" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li><strong>Human evaluation</strong> – domain experts score samples.</li>
<li><strong>Automated metrics</strong> – lexical, semantic, or reward-based.</li>
<li><strong>Verifier models</strong> – specialized LLMs assess reasoning validity.</li>
<li><strong>Regression testing</strong> – ensure no degradation after updates.</li>
</ol>
<p>Hybrid strategies combine quantitative and qualitative review for robustness.</p>
</div>
<div class="section" id="error-typology">
<h3 id="error-typology"><span class="me-2">Error Typology</span><a href="#error-typology" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="27%" />
<col width="35%" />
<col width="38%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Error Type</th>
<th class="head">Description</th>
<th class="head">Mitigation</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Factual error</strong></td>
<td>Hallucinated data</td>
<td>Retrieval grounding</td>
</tr>
<tr><td><strong>Logical error</strong></td>
<td>Invalid reasoning</td>
<td>Chain-of-thought verification</td>
</tr>
<tr><td><strong>Formatting error</strong></td>
<td>Incorrect output structure</td>
<td>Schema validation</td>
</tr>
<tr><td><strong>Omission error</strong></td>
<td>Missing key information</td>
<td>Instruction specificity</td>
</tr>
<tr><td><strong>Bias / Toxicity</strong></td>
<td>Value misalignment</td>
<td>Ethical fine-tuning</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div class="section" id="human-alignment">
<h2 id="human-alignment"><span class="me-2">Human Alignment</span><a href="#human-alignment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id39">
<h3 id="id39"><span class="me-2">Definition</span><a href="#id39" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Human alignment</strong> ensures that LLM outputs adhere to ethical norms, user intentions, and contextual appropriateness.</p>
<p><strong>Two main paradigms exist</strong></p>
<ol class="arabic simple">
<li><strong>Reinforcement Learning from Human Feedback (RLHF)</strong></li>
<li><strong>Constitutional AI (CAI)</strong></li>
</ol>
</div>
<div class="section" id="reinforcement-learning-from-human-feedback">
<h3 id="reinforcement-learning-from-human-feedback"><span class="me-2">Reinforcement Learning from Human Feedback</span><a href="#reinforcement-learning-from-human-feedback" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>RLHF involves three stages</strong></p>
<ol class="arabic simple">
<li><strong>Supervised Fine-Tuning (SFT)</strong>
- Model trained on human demonstration pairs (prompt → preferred response).</li>
<li><strong>Reward Modeling</strong>
- Separate model learns to predict human preference scores.</li>
<li><strong>Policy Optimization</strong>
- Main LLM fine-tuned using reinforcement learning (e.g., PPO) to maximize reward.</li>
</ol>
<p><strong>Objective function</strong></p>
<div class="math">
\begin{equation*}
\max_{\theta} \mathbb{E}_{x \sim D} [ R(f_{\theta}(x)) ]
\end{equation*}
</div>
<p>where <span class="math">\(R\)</span> is the learned reward function.</p>
</div>
<div class="section" id="constitutional-ai">
<h3 id="constitutional-ai"><span class="me-2">Constitutional AI</span><a href="#constitutional-ai" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Instead of relying on human labels, the model critiques and revises its own outputs using a written constitution of ethical rules.</p>
<p><strong>Example</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Principle: Do not include private or harmful information.
</span><span class="line">Critique: The following paragraph violates the rule by revealing identity details.
</span><span class="line">Revision: Replace identifiers with anonymized descriptions.
</span></code></pre></td></tr></table></div></div></figure><p><strong>Advantages</strong>
- Scalable and consistent.</p>
<ul class="simple">
<li>Reduces dependence on expensive human labeling.</li>
<li>Enables transparent reasoning about ethical compliance.</li>
</ul>
</div>
<div class="section" id="hybrid-alignment-approaches">
<h3 id="hybrid-alignment-approaches"><span class="me-2">Hybrid Alignment Approaches</span><a href="#hybrid-alignment-approaches" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Combining RLHF with CAI yields balance between empirical grounding and principled reasoning.
Systems like <strong>Claude 3.5</strong> and <strong>GPT-4-turbo</strong> employ such hybrid training.</p>
</div>
</div>
<div class="section" id="ethical-and-societal-implications">
<h2 id="ethical-and-societal-implications"><span class="me-2">Ethical and Societal Implications</span><a href="#ethical-and-societal-implications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineers influence how AI systems interpret and enact human intent.
<strong>Key considerations</strong></p>
<ol class="arabic simple">
<li><strong>Bias Amplification</strong> – Avoid prompts reinforcing stereotypes.</li>
<li><strong>Data Privacy</strong> – Never leak or synthesize sensitive information.</li>
<li><strong>Transparency</strong> – Document prompt design and purpose.</li>
<li><strong>Accountability</strong> – Include provenance and traceability in outputs.</li>
<li><strong>Interpretability</strong> – Prefer prompts that expose reasoning, not hide it.</li>
</ol>
<p>Emerging ethical standards (ISO/IEC 42001, NIST AI RMF) treat prompt design as part of responsible AI lifecycle.</p>
</div>
<div class="section" id="advanced-methodologies">
<h2 id="advanced-methodologies"><span class="me-2">Advanced Methodologies</span><a href="#advanced-methodologies" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="prompt-ensembles">
<h3 id="prompt-ensembles"><span class="me-2">Prompt Ensembles</span><a href="#prompt-ensembles" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Use multiple prompts targeting the same task; combine outputs by voting, ranking, or reward scoring.</p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Prompt A → Output 1
</span><span class="line">Prompt B → Output 2
</span><span class="line">Prompt C → Output 3
</span><span class="line">Select best via verifier
</span></code></pre></td></tr></table></div></div></figure><p>Improves robustness to noise and linguistic variation.</p>
</div>
<div class="section" id="id40">
<h3 id="id40"><span class="me-2">Meta-Prompting</span><a href="#id40" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Prompts that <em>generate or evaluate</em> other prompts.</p>
<p><strong>Example</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>Task: Design an optimized prompt for evaluating research abstracts.
</span><span class="line">Constraints: Must measure novelty, clarity, and reproducibility.
</span></code></pre></td></tr></table></div></div></figure><p>Enables automation of prompt engineering itself.</p>
</div>
<div class="section" id="prompt-grammars">
<h3 id="prompt-grammars"><span class="me-2">Prompt Grammars</span><a href="#prompt-grammars" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Formal rule-based systems defining valid prompt structure.
Used for LLM orchestration and safety assurance.</p>
<p><strong>Example grammar fragment (EBNF style)</strong></p>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="text"><span class="line"><span></span>&lt;prompt&gt; ::= &lt;role&gt; &quot;:&quot; &lt;instruction&gt; &quot;.&quot; &lt;constraints&gt;?
</span><span class="line">&lt;role&gt; ::= &quot;You are&quot; &lt;persona&gt;
</span><span class="line">&lt;constraints&gt; ::= &quot;Follow these rules:&quot; &lt;rule_list&gt;
</span></code></pre></td></tr></table></div></div></figure><p>Automated prompt grammars reduce malformed or unsafe prompt inputs in production pipelines.</p>
</div>
</div>
<div class="section" id="scaling-and-maintenance">
<h2 id="scaling-and-maintenance"><span class="me-2">Scaling and Maintenance</span><a href="#scaling-and-maintenance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>In enterprise contexts, prompt systems evolve continuously.</p>
<p><strong>Best practices</strong></p>
<ul class="simple">
<li><strong>Version control:</strong> store each iteration with metadata.</li>
<li><strong>Benchmark suite:</strong> track longitudinal performance.</li>
<li><strong>A/B testing:</strong> compare prompt variants statistically.</li>
<li><strong>Monitoring:</strong> detect drift or degradation over time.</li>
<li><strong>Retraining triggers:</strong> schedule updates when failure rate exceeds threshold.</li>
</ul>
<p>Prompt Lifecycle Management resembles traditional software engineering, with prompts as versioned code artifacts.</p>
</div>
<div class="section" id="future-directions">
<h2 id="future-directions"><span class="me-2">Future Directions</span><a href="#future-directions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li><strong>Neuro-symbolic prompting</strong>
- Integrating structured logic reasoning modules within neural prompting loops.</li>
<li><strong>Adaptive prompt optimization</strong>
- Real-time tuning via continuous evaluation.</li>
<li><strong>Cross-modal prompting</strong>
- Unified prompts controlling text, image, audio, and code models.</li>
<li><strong>Prompt programming languages</strong>
- Formal DSLs for composable prompt design (e.g., Guidance, DSPy).</li>
<li><strong>Autonomous prompt ecosystems</strong>
- Agents generating, evaluating, and deploying prompts automatically.</li>
</ol>
</div>
<div class="section" id="id41">
<h2 id="id41"><span class="me-2">Conceptual Summary</span><a href="#id41" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li>Expert-level prompt engineering treats language interfaces as controllable systems.</li>
<li>Structured templates, chains, and meta-prompts improve reliability.</li>
<li>Evaluation metrics and verifier models replace subjective assessment.</li>
<li>Alignment frameworks (RLHF, CAI) connect AI reasoning to human ethics.</li>
<li>Continuous optimization and lifecycle management sustain long-term robustness.</li>
</ol>
</div>
<div class="section" id="id42">
<h2 id="id42"><span class="me-2">Transition to Next Section</span><a href="#id42" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Final section (Part 6) will integrate all prior elements into a unified conceptual model,
linking the evolution from simple prompting to reasoning agents aligned with human goals.</p>
</div>
<div class="section" id="part-6-unification-frameworks-and-future-landscape">
<h2 id="part-6-unification-frameworks-and-future-landscape"><span class="me-2">Part 6 – Unification, Frameworks, and Future Landscape</span><a href="#part-6-unification-frameworks-and-future-landscape" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>
<div class="section" id="id43">
<h2 id="id43"><span class="me-2">Overview</span><a href="#id43" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering has evolved from a craft of phrasing to a full-stack discipline bridging linguistics, cognitive science, and software engineering.
This final section consolidates previous concepts into a coherent framework for expert practitioners and outlines future trajectories of the field.</p>
</div>
<div class="section" id="unified-conceptual-model-of-prompt-systems">
<h2 id="unified-conceptual-model-of-prompt-systems"><span class="me-2">Unified Conceptual Model of Prompt Systems</span><a href="#unified-conceptual-model-of-prompt-systems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="id44">
<h3 id="id44"><span class="me-2">Definition</span><a href="#id44" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>A <strong>prompt system</strong> is a complete architecture that manages the generation, evaluation, and improvement of LLM responses through designed textual interfaces and structured computation.</p>
<p><strong>The system integrates four primary layers</strong></p>
<ol class="arabic simple">
<li><strong>Prompt Layer</strong> — Natural language interface and templates.</li>
<li><strong>Reasoning Layer</strong> — Internal inference and chain-of-thought control.</li>
<li><strong>Tool Layer</strong> — Integration with external actions, databases, or APIs.</li>
<li><strong>Evaluation Layer</strong> — Continuous assessment and alignment mechanisms.</li>
</ol>
<p>These layers form a <strong>feedback-controlled cognitive loop</strong> analogous to a control system in engineering.</p>
</div>
<div class="section" id="mathematical-analogy">
<h3 id="mathematical-analogy"><span class="me-2">Mathematical Analogy</span><a href="#mathematical-analogy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p><strong>Let</strong></p>
<ul class="simple">
<li><span class="math">\(u\)</span> = user input (goal / query)</li>
<li><span class="math">\(y\)</span> = LLM output</li>
<li><span class="math">\(e = y^* - y\)</span> = deviation from ideal response</li>
<li><span class="math">\(P\)</span> = prompt function</li>
<li><span class="math">\(C\)</span> = controller adjusting prompt parameters</li>
</ul>
<p><strong>Then</strong></p>
<div class="math">
\begin{equation*}
y = P(u, \theta) , \quad \theta = C(e)
\end{equation*}
</div>
<p>Prompt engineering aims to minimize <span class="math">\(e\)</span> through iterative adaptation of <span class="math">\(\theta\)</span>.</p>
</div>
</div>
<div class="section" id="frameworks-for-structured-prompting">
<h2 id="frameworks-for-structured-prompting"><span class="me-2">Frameworks for Structured Prompting</span><a href="#frameworks-for-structured-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="section" id="guideline-frameworks">
<h3 id="guideline-frameworks"><span class="me-2">Guideline Frameworks</span><a href="#guideline-frameworks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="13%" />
<col width="51%" />
<col width="36%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Framework</th>
<th class="head">Core Idea</th>
<th class="head">Typical Use</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>CO-STAR</strong></td>
<td>Context, Objective, Style, Tone, Audience, Response</td>
<td>Business communication</td>
</tr>
<tr><td><strong>RACE</strong></td>
<td>Role, Action, Context, Expectation</td>
<td>Instructional prompting</td>
</tr>
<tr><td><strong>TACTIC</strong></td>
<td>Task, Audience, Context, Tone, Intent, Constraints</td>
<td>Content creation</td>
</tr>
<tr><td><strong>TREE</strong></td>
<td>Task, Reasoning, Examples, Evaluation</td>
<td>Analytical prompting</td>
</tr>
<tr><td><strong>MATE</strong></td>
<td>Motivation, Action, Target, Evaluation</td>
<td>Persuasive or goal-oriented prompts</td>
</tr>
</tbody>
</table></div>
<p>These frameworks standardize prompt structure and ensure reproducibility.</p>
</div>
<div class="section" id="programmatic-frameworks">
<h3 id="programmatic-frameworks"><span class="me-2">Programmatic Frameworks</span><a href="#programmatic-frameworks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol class="arabic simple">
<li><strong>LangChain</strong>
- Modular chaining of prompts, memory, and tools.<ul>
<li>Abstracts agents, retrievers, and evaluators.</li>
</ul>
</li>
<li><strong>LlamaIndex</strong>
- Specialized for retrieval augmentation and knowledge graph construction.</li>
<li><strong>DSPy</strong>
- Declarative syntax for dataflow-style prompt orchestration.</li>
</ol>
<p><strong>- Example</strong></p>
<blockquote>
<figure class="code"><div class="highlight"><div class="table-wrapper"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="nd">@dspy</span><span class="o">.</span><span class="n">prompt</span><span class="p">(</span><span class="s2">&quot;Summarize research paper </span><span class="si">{title}</span><span class="s2"> with focus on </span><span class="si">{topic}</span><span class="s2">.&quot;</span><span class="p">)</span>
</span><span class="line"><span class="k">def</span> <span class="nf">summarize</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">topic</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">    <span class="k">pass</span>
</span></code></pre></td></tr></table></div></div></figure></blockquote>
<ol class="arabic simple" start="4">
<li><strong>Guidance / Outlines</strong>
- DSL-based prompt control with token-by-token validation.</li>
<li><strong>Semantic Kernel</strong>
- Microsoft framework treating skills as callable AI functions.</li>
</ol>
<p>Together, these frameworks transform prompt design from ad-hoc text to software-defined pipelines.</p>
</div>
</div>
<div class="section" id="cognitive-and-linguistic-insights">
<h2 id="cognitive-and-linguistic-insights"><span class="me-2">Cognitive and Linguistic Insights</span><a href="#cognitive-and-linguistic-insights" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering increasingly leverages cognitive linguistics and psycholinguistics to model how LLMs interpret instructions.</p>
<p><strong>Core insights</strong></p>
<ul class="simple">
<li><strong>Framing effect:</strong> Slight wording changes shift probabilistic activation.</li>
<li><strong>Priming:</strong> Early context defines latent vector space trajectory.</li>
<li><strong>Anchoring:</strong> Initial examples bias continuation direction.</li>
<li><strong>Recency weighting:</strong> Tokens near the end of the context disproportionately influence output.</li>
<li><strong>Cognitive load:</strong> Excessive complexity in one prompt reduces focus and coherence.</li>
</ul>
<p>Design implication: clarity, hierarchy, and progressive disclosure yield better reasoning outcomes.</p>
</div>
<div class="section" id="interdisciplinary-connections">
<h2 id="interdisciplinary-connections"><span class="me-2">Interdisciplinary Connections</span><a href="#interdisciplinary-connections" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="34%" />
<col width="66%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Discipline</th>
<th class="head">Relevance to Prompt Engineering</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Cognitive Science</strong></td>
<td>Understanding reasoning and bias in LLM inference.</td>
</tr>
<tr><td><strong>Linguistics</strong></td>
<td>Syntax, pragmatics, and discourse structuring.</td>
</tr>
<tr><td><strong>Software Engineering</strong></td>
<td>Version control, testing, automation.</td>
</tr>
<tr><td><strong>Information Retrieval</strong></td>
<td>RAG, memory search, and context curation.</td>
</tr>
<tr><td><strong>Ethics and Philosophy</strong></td>
<td>Alignment, intent, and responsibility.</td>
</tr>
</tbody>
</table></div>
<p>Prompt engineering thus sits at the intersection of technical precision and human communication theory.</p>
</div>
<div class="section" id="scaling-laws-and-systemic-limits">
<h2 id="scaling-laws-and-systemic-limits"><span class="me-2">Scaling Laws and Systemic Limits</span><a href="#scaling-laws-and-systemic-limits" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Empirical scaling laws describe diminishing returns with parameter growth.
Reasoning and retrieval improvements now drive major performance leaps at smaller scales.</p>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="27%" />
<col width="32%" />
<col width="41%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Dimension</th>
<th class="head">Scaling Benefit</th>
<th class="head">Limiting Factor</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Model size</td>
<td>Smooth improvement</td>
<td>Cost and latency</td>
</tr>
<tr><td>Context length</td>
<td>Expanded reasoning</td>
<td>Attention inefficiency</td>
</tr>
<tr><td>Training data</td>
<td>Knowledge coverage</td>
<td>Noise and bias saturation</td>
</tr>
<tr><td>Test-time compute</td>
<td>Reasoning quality</td>
<td>Inference cost</td>
</tr>
<tr><td>Tool integration</td>
<td>Real-world capability</td>
<td>Complexity of orchestration</td>
</tr>
</tbody>
</table></div>
<p>The modern optimization frontier balances all dimensions simultaneously.</p>
</div>
<div class="section" id="automation-of-prompt-engineering">
<h2 id="automation-of-prompt-engineering"><span class="me-2">Automation of Prompt Engineering</span><a href="#automation-of-prompt-engineering" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Emerging systems increasingly automate prompt generation and testing.</p>
<p><strong>Automation pipelines typically include</strong></p>
<ol class="arabic simple">
<li><strong>Prompt generator</strong> — produces candidate prompts from meta-specifications.</li>
<li><strong>Evaluator</strong> — scores each output using reward models or verifiers.</li>
<li><strong>Optimizer</strong> — updates prompt templates via gradient-free or RL search.</li>
<li><strong>Deployer</strong> — selects best-performing prompt for live use.</li>
</ol>
<p>This mirrors AutoML paradigms applied to linguistic interfaces.</p>
<p><strong>Terminology</strong></p>
<ul class="simple">
<li><strong>AutoPrompting:</strong> end-to-end pipeline for automated prompt design.</li>
<li><strong>Prompt Compiler:</strong> software that translates human intent into structured prompt graphs.</li>
<li><strong>Prompt Policy:</strong> adaptive selection rule determining which prompt variant to use per context.</li>
</ul>
</div>
<div class="section" id="humanai-collaboration-paradigm">
<h2 id="humanai-collaboration-paradigm"><span class="me-2">Human–AI Collaboration Paradigm</span><a href="#humanai-collaboration-paradigm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering embodies <em>symbiotic cognition</em>: humans and models co-reason in shared linguistic space.</p>
<ul class="simple">
<li>Humans contribute <strong>intent</strong>, <strong>values</strong>, and <strong>contextual understanding</strong>.</li>
<li>LLMs contribute <strong>speed</strong>, <strong>breadth</strong>, and <strong>combinatorial search</strong>.</li>
</ul>
<p>The interface becomes a <strong>joint cognitive workspace</strong> where prompts act as mutual protocols.</p>
<p><strong>Key properties of effective collaboration</strong></p>
<ol class="arabic simple">
<li>Explicit goal communication.</li>
<li>Iterative refinement and feedback.</li>
<li>Trust through transparency.</li>
<li>Measurable accountability.</li>
</ol>
</div>
<div class="section" id="societal-and-industrial-impact">
<h2 id="societal-and-industrial-impact"><span class="me-2">Societal and Industrial Impact</span><a href="#societal-and-industrial-impact" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>Prompt engineering underpins multiple industries</strong></p>
<ul class="simple">
<li><strong>Education:</strong> adaptive tutoring and automated assessment.</li>
<li><strong>Medicine:</strong> clinical summarization, differential reasoning.</li>
<li><strong>Law:</strong> contract analysis and compliance review.</li>
<li><strong>Finance:</strong> risk modeling, regulatory summarization.</li>
<li><strong>Science:</strong> literature synthesis and hypothesis generation.</li>
<li><strong>Creative arts:</strong> text, image, and multimedia synthesis.</li>
</ul>
<p>Organizations now maintain <strong>PromptOps</strong> pipelines for systematic prompt management akin to DevOps.</p>
</div>
<div class="section" id="ecosystem-integration">
<h2 id="ecosystem-integration"><span class="me-2">Ecosystem Integration</span><a href="#ecosystem-integration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>Modern LLM systems operate as composable services</strong></p>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="39%" />
<col width="39%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Layer</th>
<th class="head">Function</th>
<th class="head">Example Tools</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><strong>Interface</strong></td>
<td>Human interaction</td>
<td>Chat UIs, voice agents</td>
</tr>
<tr><td><strong>Reasoning</strong></td>
<td>Controlled text generation</td>
<td>GPT, Claude, Gemini</td>
</tr>
<tr><td><strong>Retrieval</strong></td>
<td>Contextual augmentation</td>
<td>FAISS, Pinecone</td>
</tr>
<tr><td><strong>Execution</strong></td>
<td>Function calls</td>
<td>LangChain Tools, SK Skills</td>
</tr>
<tr><td><strong>Evaluation</strong></td>
<td>Monitoring and metrics</td>
<td>OpenDevin, PromptLayer</td>
</tr>
</tbody>
</table></div>
<p>The complete stack represents the <strong>AI Reasoning Operating System (AI-ROS)</strong> — a conceptual architecture combining all reasoning, memory, and action subsystems under unified control.</p>
</div>
<div class="section" id="the-future-of-prompt-engineering">
<h2 id="the-future-of-prompt-engineering"><span class="me-2">The Future of Prompt Engineering</span><a href="#the-future-of-prompt-engineering" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p><strong>Key forecasted trends</strong></p>
<ol class="arabic simple">
<li><strong>Prompt Programming Languages (PPLs):</strong>
- DSLs combining natural and formal syntax.<ul>
<li>Enable declarative prompt composition and safety guarantees.</li>
</ul>
</li>
<li><strong>Dynamic Prompting:</strong>
- Prompts that adapt in real time using environmental feedback.</li>
<li><strong>Cognitive Emulation:</strong>
- Multi-agent reasoning loops imitating human deliberation structures.</li>
<li><strong>Regulatory Standardization:</strong>
- Industry-wide specifications for transparency, safety, and reproducibility.</li>
<li><strong>Embedded Prompt Ecosystems:</strong>
- Prompts compiled directly into chip-level or edge model firmware.</li>
<li><strong>Semantic Networks of Prompts:</strong>
- Graph-based prompt repositories enabling search and reuse across tasks.</li>
</ol>
</div>
<div class="section" id="synthesis-from-words-to-systems">
<h2 id="synthesis-from-words-to-systems"><span class="me-2">Synthesis: From Words to Systems</span><a href="#synthesis-from-words-to-systems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering began as linguistic experimentation and now functions as system design.
Every improvement — from prompt phrasing to test-time reasoning — contributes to a continuous feedback loop between human thought and machine cognition.</p>
<p><strong>Hierarchy of abstraction</strong></p>
<div class="table-wrapper"><table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="26%" />
<col width="41%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Level</th>
<th class="head">Focus</th>
<th class="head">Artifact</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><ol class="first last arabic simple">
<li>Token</li>
</ol>
</td>
<td>Representation</td>
<td>Embedding vectors</td>
</tr>
<tr><td><ol class="first last arabic simple" start="2">
<li>Prompt</li>
</ol>
</td>
<td>Instruction</td>
<td>Text templates</td>
</tr>
<tr><td><ol class="first last arabic simple" start="3">
<li>Reasoning Chain</li>
</ol>
</td>
<td>Process</td>
<td>Thought tokens</td>
</tr>
<tr><td><ol class="first last arabic simple" start="4">
<li>Agent</li>
</ol>
</td>
<td>Behavior</td>
<td>Goal-driven loops</td>
</tr>
<tr><td><ol class="first last arabic simple" start="5">
<li>Ecosystem</li>
</ol>
</td>
<td>System</td>
<td>Distributed AI networks</td>
</tr>
</tbody>
</table></div>
<p>Each layer refines control and interpretability.
Future systems will likely unify these layers under a single adaptive architecture.</p>
</div>
<div class="section" id="key-takeaways">
<h2 id="key-takeaways"><span class="me-2">Key Takeaways</span><a href="#key-takeaways" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ol class="arabic simple">
<li>Prompt engineering is both linguistic precision and systems engineering.</li>
<li>Mastery requires understanding transformers, reasoning, and alignment.</li>
<li>Reasoning LLMs and agents mark a paradigm shift from static prediction to dynamic cognition.</li>
<li>Human alignment ensures safe and ethical integration into society.</li>
<li>Automation and standardization will transform prompt design into a formal software discipline.</li>
</ol>
</div>
<div class="section" id="conclusion">
<h2 id="conclusion"><span class="me-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>Prompt engineering represents humanity’s most direct tool for shaping artificial cognition.
It is the dialogue layer between symbolic intent and statistical intelligence.
As LLMs evolve into autonomous agents, prompt engineers become architects of cognitive infrastructure.</p>
<p><strong>In essence:</strong>
&gt; Prompt engineering is not merely about crafting words —
&gt; it is about constructing reasoning systems that think, act, and align with human purpose.</p>
</div>
<div class="section" id="appendix-suggested-readings-and-references">
<h2 id="appendix-suggested-readings-and-references"><span class="me-2">Appendix: Suggested Readings and References</span><a href="#appendix-suggested-readings-and-references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul class="simple">
<li>OpenAI (2024). <em>GPT-4 Technical Report.</em></li>
<li>Anthropic (2024). <em>Constitutional AI: Harmlessness from AI Feedback.</em></li>
<li>DeepSeek (2025). <em>Reasoning LLMs and Test-Time Scaling.</em></li>
<li>Yao et al. (2022). <em>ReAct: Synergizing Reasoning and Acting in Language Models.</em></li>
<li>Ouyang et al. (2022). <em>Training language models to follow instructions with human feedback.</em></li>
<li>Kaplan et al. (2020). <em>Scaling Laws for Neural Language Models.</em></li>
<li>Chinchilla (DeepMind, 2022). <em>Compute-optimal large language model scaling.</em></li>
<li>Maarten Grootendorst (2024). <em>Visual Guides to LLM Agents and Reasoning LLMs.</em></li>
<li>LearnPrompting.org &amp; PromptingGuide.ai (2023–2025). <em>Prompting fundamentals and applied patterns.</em></li>
</ul>
</div>
<div class="section" id="end-of-document">
<h2 id="end-of-document"><span class="me-2">End of Document</span><a href="#end-of-document" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
</div>


  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/posts/categories/prompt/">prompt</a>,
          <a href="/posts/categories/engineering/">engineering</a>,
          <a href="/posts/categories/llms/">llms</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/posts/tags/prompt-engineering/"
            class="post-tag no-text-decoration"
          >prompt-engineering</a>
        
          <a
            href="/posts/tags/llms/"
            class="post-tag no-text-decoration"
          >llms</a>
        
          <a
            href="/posts/tags/chain-of-thought/"
            class="post-tag no-text-decoration"
          >chain-of-thought</a>
        
          <a
            href="/posts/tags/tree-of-thought/"
            class="post-tag no-text-decoration"
          >tree-of-thought</a>
        
          <a
            href="/posts/tags/rag/"
            class="post-tag no-text-decoration"
          >rag</a>
        
          <a
            href="/posts/tags/react/"
            class="post-tag no-text-decoration"
          >react</a>
        
          <a
            href="/posts/tags/agents/"
            class="post-tag no-text-decoration"
          >agents</a>
        
          <a
            href="/posts/tags/alignment/"
            class="post-tag no-text-decoration"
          >alignment</a>
        
          <a
            href="/posts/tags/evaluation/"
            class="post-tag no-text-decoration"
          >evaluation</a>
        
          <a
            href="/posts/tags/reasoning/"
            class="post-tag no-text-decoration"
          >reasoning</a>
        
          <a
            href="/posts/tags/test-time-compute/"
            class="post-tag no-text-decoration"
          >test-time-compute</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=Comprehensive%20Guide%20to%20Prompt%20Engineering%20and%20LLMs%20-%20Posts%20by%20MR901&url=https%3A%2F%2Fmr901.github.io%2Fposts%2Fprompting-engineering%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://www.facebook.com/sharer/sharer.php?title=Comprehensive%20Guide%20to%20Prompt%20Engineering%20and%20LLMs%20-%20Posts%20by%20MR901&u=https%3A%2F%2Fmr901.github.io%2Fposts%2Fprompting-engineering%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook">
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=https%3A%2F%2Fmr901.github.io%2Fposts%2Fprompting-engineering%2F&text=Comprehensive%20Guide%20to%20Prompt%20Engineering%20and%20LLMs%20-%20Posts%20by%20MR901" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/udemy-course-open-source-llms/">(Udemy Course) Open-Source LLMs: Uncensored & Secure AI Locally with RAG</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/multithreading-vs-multiprocessing/">Multithreading vs Multiprocessing — Choosing the Right Concurrency Model</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/understanding-docker/">Docker — A Complete Practical Guide for Engineers and DevOps</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/understanding-mongodb/">MongoDB — A Complete Practical Guide for Engineers and Data Practitioners</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/a-complete-guide-to-mlflow/">A Complete Guide to MLflow</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/deployment/">deployment</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/jekyll/">jekyll</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/actions/">actions</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/gh-cli/">gh-cli</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/github/">github</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/nosql/">NoSQL</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/pages/">pages</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/performance/">performance</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/rag/">rag</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/reasoning/">reasoning</a>
      
    </div>
  </section>


            </div>

            
              
              






  <div class="toc-border-cover z-3"></div>
  <section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4">
    <h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->















  

  

  

  

  

  

  

  

  

  

  

  

  

  
    










  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/udemy-course-open-source-llms/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1762194600"
  data-df="ll"
  
>
  Nov  4, 2025
</time>

              <h4 class="pt-0 my-2">(Udemy Course) Open-Source LLMs: Uncensored & Secure AI Locally with RAG</h4>
              <div class="text-muted">
                <p>A comprehensive learning journey through open-source LLMs—from local setup to production agents. Course notes covering Llama3, Mistral, RAG, vector databases, LangChain, and AI agents.</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/laws-of-life/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1761071400"
  data-df="ll"
  
>
  Oct 22, 2025
</time>

              <h4 class="pt-0 my-2">Laws and Principles That Shape Thinking and Decision-Making</h4>
              <div class="text-muted">
                <p>A structured overview of foundational laws, principles, and heuristics that guide reasoning, planning, and system thinking. Useful for engineering, strategy, product, and personal effectiveness.</p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/github-pages-from-zero-to-live/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>GitHub Pages: From Zero to Live</p>
    </a>
  

  
    <a
      href="/posts/laws-of-life/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>Laws and Principles That Shape Thinking and Decision-Making</p>
    </a>
  
</nav>

            

            <!-- The Footer -->
<link rel="stylesheet" href="/posts/assets/css/rst-overrides.css">

<!-- Mermaid Zoom Enhancement (loaded on all pages, activates only when mermaid diagrams present) -->
<link rel="stylesheet" href="/posts/assets/css/mermaid-zoom.css">
<script src="/posts/assets/js/mermaid-zoom.js" defer></script>

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>©
    <time>2025</time>

    
      <a href="https://github.com/mr901">Mohit Rajput</a>.
    

    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p><!-- Removed Chirpy theme reference -->
    Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center d-none">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/deployment/">deployment</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/jekyll/">jekyll</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/actions/">actions</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/gh-cli/">gh-cli</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/github/">github</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/nosql/">NoSQL</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/pages/">pages</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/performance/">performance</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/rag/">rag</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/posts/tags/reasoning/">reasoning</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div>

    

    <!-- Embedded scripts -->

    
      
      <!-- The comments switcher -->


    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  
  document.addEventListener('DOMContentLoaded', () => {
    SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('search-results'),
      json: '/posts/assets/js/data/search.json',
      searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{content}</p>  </article>',
      noResultsText: '<p class="mt-5">Oops! No results found.</p>',
      templateMiddleware: function(prop, value, template) {
        if (prop === 'categories') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
          }
        }

        if (prop === 'tags') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
          }
        }
      }
    });
  });
</script>

  </body>
</html>

